{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fastai_style_transfer.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMujkSOcfwUfkcG8Iwihf8w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stemgene/Pytorch_training/blob/master/Fastai_style_transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWPT1do4ofwV",
        "colab_type": "text"
      },
      "source": [
        "https://github.com/ZeweiChu/PyTorch-Course/blob/master/notebooks/\n",
        "\n",
        "https://github.com/zhanghang1989/PyTorch-Multi-Style-Transfer\n",
        "\n",
        "http://francescopochetti.com/style-transfer-with-fast-ai-and-pytorch/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8PELtYzmgpM",
        "colab_type": "text"
      },
      "source": [
        "## 什么是PyTorch?\n",
        "\n",
        "PyTorch是一个基于Python的科学计算库，它有以下特点:\n",
        "\n",
        "* 类似于NumPy，但是它可以使用GPU\n",
        "* 可以用它定义深度学习模型，可以灵活地进行深度学习模型的训练和使用"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfShlVgLAkXF",
        "colab_type": "text"
      },
      "source": [
        "### Tensors\n",
        "\n",
        "Tensor类似与NumPy的ndarray，唯一的区别是Tensor可以在GPU上加速运算。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8lhu82jmSrQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AuOv5JHmqx8",
        "colab_type": "text"
      },
      "source": [
        "构造一个未初始化的5x3矩阵:  未初始化: very large or small"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kFzmLvRBHGL",
        "colab_type": "code",
        "outputId": "6284df4d-b734-476d-a920-65520d4c373b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "x = torch.empty(5, 3)\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4.9657e-36, 0.0000e+00, 0.0000e+00],\n",
              "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
              "        [0.0000e+00, 0.0000e+00, 2.8026e-45],\n",
              "        [0.0000e+00, 1.1210e-44, 0.0000e+00],\n",
              "        [1.4013e-45, 0.0000e+00, 0.0000e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6FB59bABpPm",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "构建一个随机初始化的矩阵:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvGP0eKVBqQe",
        "colab_type": "code",
        "outputId": "64e622ab-3a2a-409e-dded-33dfaf2abf4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "x = torch.rand(5, 3)\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4527, 0.3758, 0.5167],\n",
              "        [0.7446, 0.2886, 0.4652],\n",
              "        [0.5858, 0.5637, 0.1437],\n",
              "        [0.9325, 0.1720, 0.8560],\n",
              "        [0.2352, 0.0334, 0.4608]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSdueqQPCEfQ",
        "colab_type": "text"
      },
      "source": [
        "构建一个全部为0，类型为long的矩阵(long int):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxNlSmU5CEFx",
        "colab_type": "code",
        "outputId": "7e7c0bf3-7b35-4f63-9581-55bc8278e13c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.zeros(5,3)\n",
        "x.dtype"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0244_zyCkFo",
        "colab_type": "code",
        "outputId": "7d636044-dcbc-4a99-f623-2d5c06f99ce6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.zeros(5,3, dtype=torch.long)\n",
        "x.dtype"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4S17Xq_yC1FO",
        "colab_type": "code",
        "outputId": "fcc39658-2192-41aa-d508-523efa531dcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.zeros(5,3).long()\n",
        "x.dtype"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oOtpaZRDCOC",
        "colab_type": "text"
      },
      "source": [
        "从数据直接直接构建tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJYzPeO5DC53",
        "colab_type": "code",
        "outputId": "53d2e54f-5f3c-451f-c8ee-d367dc3bfbbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.tensor([5.5, 3])\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5.5000, 3.0000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Hl5_lS4DMm-",
        "colab_type": "text"
      },
      "source": [
        "也可以从一个已有的tensor构建一个tensor。这些方法会重用原来tensor的特征，例如，数据类型，除非提供新的数据。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DMcOoXODNTG",
        "colab_type": "code",
        "outputId": "06007348-0c96-4095-b5b1-21e720e3a869",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "x = x.new_ones(5,3)\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azRy7d78DcZn",
        "colab_type": "code",
        "outputId": "d8acf030-df02-4f3f-c4e0-747dd28d510b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "x = x.new_ones(5,3, dtype=torch.double)\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IElXdJPDn8e",
        "colab_type": "code",
        "outputId": "33576168-41fc-43aa-fe6c-a1bf0cb074c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "x = torch.rand_like(x, dtype=torch.float)\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8707, 0.1382, 0.2775],\n",
              "        [0.9789, 0.8968, 0.9993],\n",
              "        [0.6050, 0.7385, 0.6711],\n",
              "        [0.2902, 0.9769, 0.0698],\n",
              "        [0.4830, 0.7638, 0.6863]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_AJTCvkLllo",
        "colab_type": "code",
        "outputId": "27d34fa5-a9ae-47b3-cf91-7816a486ee31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "dir(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['T',\n",
              " '__abs__',\n",
              " '__add__',\n",
              " '__and__',\n",
              " '__array__',\n",
              " '__array_priority__',\n",
              " '__array_wrap__',\n",
              " '__bool__',\n",
              " '__class__',\n",
              " '__contains__',\n",
              " '__deepcopy__',\n",
              " '__delattr__',\n",
              " '__delitem__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__div__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__float__',\n",
              " '__floordiv__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getitem__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__iadd__',\n",
              " '__iand__',\n",
              " '__idiv__',\n",
              " '__ilshift__',\n",
              " '__imul__',\n",
              " '__index__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__int__',\n",
              " '__invert__',\n",
              " '__ior__',\n",
              " '__ipow__',\n",
              " '__irshift__',\n",
              " '__isub__',\n",
              " '__iter__',\n",
              " '__itruediv__',\n",
              " '__ixor__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__long__',\n",
              " '__lshift__',\n",
              " '__lt__',\n",
              " '__matmul__',\n",
              " '__mod__',\n",
              " '__module__',\n",
              " '__mul__',\n",
              " '__ne__',\n",
              " '__neg__',\n",
              " '__new__',\n",
              " '__nonzero__',\n",
              " '__or__',\n",
              " '__pow__',\n",
              " '__radd__',\n",
              " '__rdiv__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__reversed__',\n",
              " '__rfloordiv__',\n",
              " '__rmul__',\n",
              " '__rpow__',\n",
              " '__rshift__',\n",
              " '__rsub__',\n",
              " '__rtruediv__',\n",
              " '__setattr__',\n",
              " '__setitem__',\n",
              " '__setstate__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__sub__',\n",
              " '__subclasshook__',\n",
              " '__truediv__',\n",
              " '__weakref__',\n",
              " '__xor__',\n",
              " '_backward_hooks',\n",
              " '_base',\n",
              " '_cdata',\n",
              " '_coalesced_',\n",
              " '_dimI',\n",
              " '_dimV',\n",
              " '_grad',\n",
              " '_grad_fn',\n",
              " '_indices',\n",
              " '_is_view',\n",
              " '_make_subclass',\n",
              " '_nnz',\n",
              " '_update_names',\n",
              " '_values',\n",
              " '_version',\n",
              " 'abs',\n",
              " 'abs_',\n",
              " 'acos',\n",
              " 'acos_',\n",
              " 'add',\n",
              " 'add_',\n",
              " 'addbmm',\n",
              " 'addbmm_',\n",
              " 'addcdiv',\n",
              " 'addcdiv_',\n",
              " 'addcmul',\n",
              " 'addcmul_',\n",
              " 'addmm',\n",
              " 'addmm_',\n",
              " 'addmv',\n",
              " 'addmv_',\n",
              " 'addr',\n",
              " 'addr_',\n",
              " 'align_as',\n",
              " 'align_to',\n",
              " 'all',\n",
              " 'allclose',\n",
              " 'angle',\n",
              " 'any',\n",
              " 'apply_',\n",
              " 'argmax',\n",
              " 'argmin',\n",
              " 'argsort',\n",
              " 'as_strided',\n",
              " 'as_strided_',\n",
              " 'asin',\n",
              " 'asin_',\n",
              " 'atan',\n",
              " 'atan2',\n",
              " 'atan2_',\n",
              " 'atan_',\n",
              " 'backward',\n",
              " 'baddbmm',\n",
              " 'baddbmm_',\n",
              " 'bernoulli',\n",
              " 'bernoulli_',\n",
              " 'bfloat16',\n",
              " 'bincount',\n",
              " 'bitwise_not',\n",
              " 'bitwise_not_',\n",
              " 'bitwise_xor',\n",
              " 'bitwise_xor_',\n",
              " 'bmm',\n",
              " 'bool',\n",
              " 'byte',\n",
              " 'cauchy_',\n",
              " 'ceil',\n",
              " 'ceil_',\n",
              " 'char',\n",
              " 'cholesky',\n",
              " 'cholesky_inverse',\n",
              " 'cholesky_solve',\n",
              " 'chunk',\n",
              " 'clamp',\n",
              " 'clamp_',\n",
              " 'clamp_max',\n",
              " 'clamp_max_',\n",
              " 'clamp_min',\n",
              " 'clamp_min_',\n",
              " 'clone',\n",
              " 'coalesce',\n",
              " 'conj',\n",
              " 'contiguous',\n",
              " 'copy_',\n",
              " 'cos',\n",
              " 'cos_',\n",
              " 'cosh',\n",
              " 'cosh_',\n",
              " 'cpu',\n",
              " 'cross',\n",
              " 'cuda',\n",
              " 'cumprod',\n",
              " 'cumsum',\n",
              " 'data',\n",
              " 'data_ptr',\n",
              " 'dense_dim',\n",
              " 'dequantize',\n",
              " 'det',\n",
              " 'detach',\n",
              " 'detach_',\n",
              " 'device',\n",
              " 'diag',\n",
              " 'diag_embed',\n",
              " 'diagflat',\n",
              " 'diagonal',\n",
              " 'digamma',\n",
              " 'digamma_',\n",
              " 'dim',\n",
              " 'dist',\n",
              " 'div',\n",
              " 'div_',\n",
              " 'dot',\n",
              " 'double',\n",
              " 'dtype',\n",
              " 'eig',\n",
              " 'element_size',\n",
              " 'eq',\n",
              " 'eq_',\n",
              " 'equal',\n",
              " 'erf',\n",
              " 'erf_',\n",
              " 'erfc',\n",
              " 'erfc_',\n",
              " 'erfinv',\n",
              " 'erfinv_',\n",
              " 'exp',\n",
              " 'exp_',\n",
              " 'expand',\n",
              " 'expand_as',\n",
              " 'expm1',\n",
              " 'expm1_',\n",
              " 'exponential_',\n",
              " 'fft',\n",
              " 'fill_',\n",
              " 'fill_diagonal_',\n",
              " 'flatten',\n",
              " 'flip',\n",
              " 'float',\n",
              " 'floor',\n",
              " 'floor_',\n",
              " 'fmod',\n",
              " 'fmod_',\n",
              " 'frac',\n",
              " 'frac_',\n",
              " 'gather',\n",
              " 'ge',\n",
              " 'ge_',\n",
              " 'geometric_',\n",
              " 'geqrf',\n",
              " 'ger',\n",
              " 'get_device',\n",
              " 'grad',\n",
              " 'grad_fn',\n",
              " 'gt',\n",
              " 'gt_',\n",
              " 'half',\n",
              " 'hardshrink',\n",
              " 'has_names',\n",
              " 'histc',\n",
              " 'ifft',\n",
              " 'imag',\n",
              " 'index_add',\n",
              " 'index_add_',\n",
              " 'index_copy',\n",
              " 'index_copy_',\n",
              " 'index_fill',\n",
              " 'index_fill_',\n",
              " 'index_put',\n",
              " 'index_put_',\n",
              " 'index_select',\n",
              " 'indices',\n",
              " 'int',\n",
              " 'int_repr',\n",
              " 'inverse',\n",
              " 'irfft',\n",
              " 'is_coalesced',\n",
              " 'is_complex',\n",
              " 'is_contiguous',\n",
              " 'is_cuda',\n",
              " 'is_distributed',\n",
              " 'is_floating_point',\n",
              " 'is_leaf',\n",
              " 'is_mkldnn',\n",
              " 'is_nonzero',\n",
              " 'is_pinned',\n",
              " 'is_quantized',\n",
              " 'is_same_size',\n",
              " 'is_set_to',\n",
              " 'is_shared',\n",
              " 'is_signed',\n",
              " 'is_sparse',\n",
              " 'isclose',\n",
              " 'item',\n",
              " 'kthvalue',\n",
              " 'layout',\n",
              " 'le',\n",
              " 'le_',\n",
              " 'lerp',\n",
              " 'lerp_',\n",
              " 'lgamma',\n",
              " 'lgamma_',\n",
              " 'log',\n",
              " 'log10',\n",
              " 'log10_',\n",
              " 'log1p',\n",
              " 'log1p_',\n",
              " 'log2',\n",
              " 'log2_',\n",
              " 'log_',\n",
              " 'log_normal_',\n",
              " 'log_softmax',\n",
              " 'logdet',\n",
              " 'logical_not',\n",
              " 'logical_not_',\n",
              " 'logical_xor',\n",
              " 'logical_xor_',\n",
              " 'logsumexp',\n",
              " 'long',\n",
              " 'lstsq',\n",
              " 'lt',\n",
              " 'lt_',\n",
              " 'lu',\n",
              " 'lu_solve',\n",
              " 'map2_',\n",
              " 'map_',\n",
              " 'masked_fill',\n",
              " 'masked_fill_',\n",
              " 'masked_scatter',\n",
              " 'masked_scatter_',\n",
              " 'masked_select',\n",
              " 'matmul',\n",
              " 'matrix_power',\n",
              " 'max',\n",
              " 'mean',\n",
              " 'median',\n",
              " 'min',\n",
              " 'mm',\n",
              " 'mode',\n",
              " 'mul',\n",
              " 'mul_',\n",
              " 'multinomial',\n",
              " 'mv',\n",
              " 'mvlgamma',\n",
              " 'mvlgamma_',\n",
              " 'name',\n",
              " 'names',\n",
              " 'narrow',\n",
              " 'narrow_copy',\n",
              " 'ndim',\n",
              " 'ndimension',\n",
              " 'ne',\n",
              " 'ne_',\n",
              " 'neg',\n",
              " 'neg_',\n",
              " 'nelement',\n",
              " 'new',\n",
              " 'new_empty',\n",
              " 'new_full',\n",
              " 'new_ones',\n",
              " 'new_tensor',\n",
              " 'new_zeros',\n",
              " 'nonzero',\n",
              " 'norm',\n",
              " 'normal_',\n",
              " 'numel',\n",
              " 'numpy',\n",
              " 'orgqr',\n",
              " 'ormqr',\n",
              " 'output_nr',\n",
              " 'permute',\n",
              " 'pin_memory',\n",
              " 'pinverse',\n",
              " 'polygamma',\n",
              " 'polygamma_',\n",
              " 'pow',\n",
              " 'pow_',\n",
              " 'prelu',\n",
              " 'prod',\n",
              " 'put_',\n",
              " 'q_per_channel_axis',\n",
              " 'q_per_channel_scales',\n",
              " 'q_per_channel_zero_points',\n",
              " 'q_scale',\n",
              " 'q_zero_point',\n",
              " 'qr',\n",
              " 'qscheme',\n",
              " 'random_',\n",
              " 'real',\n",
              " 'reciprocal',\n",
              " 'reciprocal_',\n",
              " 'record_stream',\n",
              " 'refine_names',\n",
              " 'register_hook',\n",
              " 'reinforce',\n",
              " 'relu',\n",
              " 'relu_',\n",
              " 'remainder',\n",
              " 'remainder_',\n",
              " 'rename',\n",
              " 'rename_',\n",
              " 'renorm',\n",
              " 'renorm_',\n",
              " 'repeat',\n",
              " 'repeat_interleave',\n",
              " 'requires_grad',\n",
              " 'requires_grad_',\n",
              " 'reshape',\n",
              " 'reshape_as',\n",
              " 'resize',\n",
              " 'resize_',\n",
              " 'resize_as',\n",
              " 'resize_as_',\n",
              " 'retain_grad',\n",
              " 'rfft',\n",
              " 'roll',\n",
              " 'rot90',\n",
              " 'round',\n",
              " 'round_',\n",
              " 'rsqrt',\n",
              " 'rsqrt_',\n",
              " 'scatter',\n",
              " 'scatter_',\n",
              " 'scatter_add',\n",
              " 'scatter_add_',\n",
              " 'select',\n",
              " 'set_',\n",
              " 'shape',\n",
              " 'share_memory_',\n",
              " 'short',\n",
              " 'sigmoid',\n",
              " 'sigmoid_',\n",
              " 'sign',\n",
              " 'sign_',\n",
              " 'sin',\n",
              " 'sin_',\n",
              " 'sinh',\n",
              " 'sinh_',\n",
              " 'size',\n",
              " 'slogdet',\n",
              " 'smm',\n",
              " 'softmax',\n",
              " 'solve',\n",
              " 'sort',\n",
              " 'sparse_dim',\n",
              " 'sparse_mask',\n",
              " 'sparse_resize_',\n",
              " 'sparse_resize_and_clear_',\n",
              " 'split',\n",
              " 'split_with_sizes',\n",
              " 'sqrt',\n",
              " 'sqrt_',\n",
              " 'squeeze',\n",
              " 'squeeze_',\n",
              " 'sspaddmm',\n",
              " 'std',\n",
              " 'stft',\n",
              " 'storage',\n",
              " 'storage_offset',\n",
              " 'storage_type',\n",
              " 'stride',\n",
              " 'sub',\n",
              " 'sub_',\n",
              " 'sum',\n",
              " 'sum_to_size',\n",
              " 'svd',\n",
              " 'symeig',\n",
              " 't',\n",
              " 't_',\n",
              " 'take',\n",
              " 'tan',\n",
              " 'tan_',\n",
              " 'tanh',\n",
              " 'tanh_',\n",
              " 'to',\n",
              " 'to_dense',\n",
              " 'to_mkldnn',\n",
              " 'to_sparse',\n",
              " 'tolist',\n",
              " 'topk',\n",
              " 'trace',\n",
              " 'transpose',\n",
              " 'transpose_',\n",
              " 'triangular_solve',\n",
              " 'tril',\n",
              " 'tril_',\n",
              " 'triu',\n",
              " 'triu_',\n",
              " 'trunc',\n",
              " 'trunc_',\n",
              " 'type',\n",
              " 'type_as',\n",
              " 'unbind',\n",
              " 'unflatten',\n",
              " 'unfold',\n",
              " 'uniform_',\n",
              " 'unique',\n",
              " 'unique_consecutive',\n",
              " 'unsqueeze',\n",
              " 'unsqueeze_',\n",
              " 'values',\n",
              " 'var',\n",
              " 'view',\n",
              " 'view_as',\n",
              " 'where',\n",
              " 'zero_']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qThGc1_D5OA",
        "colab_type": "text"
      },
      "source": [
        "得到tensor的形状:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oo5Uq9E5D6RU",
        "colab_type": "code",
        "outputId": "10485b07-3077-4ac5-8ede-7ac43a3da1c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ4WhBJkD735",
        "colab_type": "code",
        "outputId": "c55bed9e-ba5d-4da6-d06c-27ef798b07ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#注意:``torch.Size`` 返回的是一个tuple\n",
        "x.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGUE5MQ2JmzD",
        "colab_type": "text"
      },
      "source": [
        "Resizing: 如果你希望resize/reshape一个tensor，可以使用torch.view："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gvw5yogXJqSA",
        "colab_type": "code",
        "outputId": "06665d5a-08b0-4c51-b50b-21fe8031c916",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.randn(4,4)\n",
        "y = x.view(16)\n",
        "z = x.view(-1, 8) #the size -1 is inferred from other dimensions\n",
        "print(x.size(), y.size(), z.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPeQNhzgKDxG",
        "colab_type": "text"
      },
      "source": [
        "如果你有一个只有一个元素的tensor，使用.item()方法可以把里面的value变成Python数值。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hk6_YWlPKESM",
        "colab_type": "code",
        "outputId": "9f41bdc0-f4b1-4564-8100-596be15d29c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.randn(1)\n",
        "x.item()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8007168173789978"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KBIinP4EPT2",
        "colab_type": "text"
      },
      "source": [
        "### Operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ny-pEQSnEdsi",
        "colab_type": "text"
      },
      "source": [
        "有很多种tensor运算。我们先介绍加法运算。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqO9oiQeD93c",
        "colab_type": "code",
        "outputId": "7b64b2d2-39f9-4510-db8c-ca2f4ccef5ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "y = torch.rand_like(x)\n",
        "print(x+y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.5322, 0.5965, 0.6609],\n",
            "        [1.7503, 1.7752, 1.9653],\n",
            "        [0.8923, 1.6527, 1.6047],\n",
            "        [0.4350, 1.7578, 0.2323],\n",
            "        [1.1993, 0.9583, 0.7724]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qtxl-fKeEl4R",
        "colab_type": "text"
      },
      "source": [
        "另一种着加法的写法"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FagUVMqpEmbT",
        "colab_type": "code",
        "outputId": "68b3bdc9-bf72-440f-ab16-ed87dcbd530d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "torch.add(x,y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.5322, 0.5965, 0.6609],\n",
              "        [1.7503, 1.7752, 1.9653],\n",
              "        [0.8923, 1.6527, 1.6047],\n",
              "        [0.4350, 1.7578, 0.2323],\n",
              "        [1.1993, 0.9583, 0.7724]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boHRWJiGEsti",
        "colab_type": "text"
      },
      "source": [
        "把输出作为一个变量"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2R8plhAEtWa",
        "colab_type": "code",
        "outputId": "c223b71c-a8c0-469d-de74-847e2b469f84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "result = torch.empty_like(x)\n",
        "torch.add(x,y, out=result)\n",
        "# result = x + y\n",
        "result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.5322, 0.5965, 0.6609],\n",
              "        [1.7503, 1.7752, 1.9653],\n",
              "        [0.8923, 1.6527, 1.6047],\n",
              "        [0.4350, 1.7578, 0.2323],\n",
              "        [1.1993, 0.9583, 0.7724]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUbA0KzDHLIB",
        "colab_type": "text"
      },
      "source": [
        "in-place加法, all '_' means self operation\n",
        "\n",
        "注意: \n",
        "\n",
        "任何in-place的运算都会以``_``结尾。 举例来说：``x.copy_(y)``, ``x.t_()``, 会改变 ``x``。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5tF-HvpF0-c",
        "colab_type": "code",
        "outputId": "9e5a01ba-6bd1-4c67-98f1-cc45367639b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# adds x to y\n",
        "y.add_(x)\n",
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.5322, 0.5965, 0.6609],\n",
              "        [1.7503, 1.7752, 1.9653],\n",
              "        [0.8923, 1.6527, 1.6047],\n",
              "        [0.4350, 1.7578, 0.2323],\n",
              "        [1.1993, 0.9583, 0.7724]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5ErGblpMIMt",
        "colab_type": "text"
      },
      "source": [
        "更多阅读\n",
        "\n",
        "各种Tensor operations, 包括transposing, indexing, slicing, mathematical operations, linear algebra, random numbers在 <https://pytorch.org/docs/torch>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uMEsP46F0ZQ",
        "colab_type": "text"
      },
      "source": [
        "### Index\n",
        "\n",
        "各种类似NumPy的indexing都可以在PyTorch tensor上面使用。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUoFhiC1HeK9",
        "colab_type": "code",
        "outputId": "36479011-7cbd-494c-cbca-98f81b93aff0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print(x[:, 1:])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.1382, 0.2775],\n",
            "        [0.8968, 0.9993],\n",
            "        [0.7385, 0.6711],\n",
            "        [0.9769, 0.0698],\n",
            "        [0.7638, 0.6863]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5IHSfB2HV0o",
        "colab_type": "text"
      },
      "source": [
        "## Numpy和Tensor之间的转化\n",
        "\n",
        "在Torch Tensor和NumPy array之间相互转化非常容易。\n",
        "\n",
        "Torch Tensor和NumPy array会共享内存，所以改变其中一项也会改变另一项。\n",
        "\n",
        "把Torch Tensor转变成NumPy Array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlsq_Au4McET",
        "colab_type": "code",
        "outputId": "134951cb-3f58-4ddd-9bd5-b5c9d37a907e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a = torch.ones(5)\n",
        "print(a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQ9EWhisMiQm",
        "colab_type": "code",
        "outputId": "828cd85f-9e93-48be-81a0-7f2094d6b33c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "b = a.numpy()\n",
        "print(b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 1. 1. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7E6jTtGMndN",
        "colab_type": "text"
      },
      "source": [
        "改变numpy array里面的值。 a and b change together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36hsMHZGMsgj",
        "colab_type": "code",
        "outputId": "dd3532d8-57a6-497f-f88e-7de00b50eaf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "a.add_(1)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsolXd67Mr7d",
        "colab_type": "text"
      },
      "source": [
        "把NumPy ndarray转成Torch Tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qr3Qlv3HM4gt",
        "colab_type": "code",
        "outputId": "8ee97fff-4b8e-45fc-897f-6aefb1a2b864",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import numpy as np\n",
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "np.add(a, 1, out=a)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCdQFIUQOExI",
        "colab_type": "text"
      },
      "source": [
        "## CUDA Tensors\n",
        "使用.to方法，Tensor可以被移动到别的device上。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zS2__E6IONCw",
        "colab_type": "code",
        "outputId": "f609b446-3cec-45c6-94d8-4c657392f5a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otOmugHHORCO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let us run this cell only if CUDA is available\n",
        "# We will use \"torch.device\" objects to move tensors in and out of GPU\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")              # a CUDA device object\n",
        "  y = torch.ones_like(x, device=device)      # directly create a tensor on GPU\n",
        "  x = x.to(device)                           # or just use strings '.to(\"CUDA\")'\n",
        "  z = x + y\n",
        "  print(z)\n",
        "  print(z.to('cpu', torch.double))           # '.to' can also change dtype together"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ku-PvGfOJTA",
        "colab_type": "text"
      },
      "source": [
        "If some tensor is GPU, it cannon be simply transfered to numpy or be shown, it should be transfered to CPU first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KQyLR9USF17",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y.to('cpu').data.numpy()\n",
        "y.cpu().data.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqLtcQRBSo_a",
        "colab_type": "text"
      },
      "source": [
        "set a whole model to CUDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf8j-aJPSs7d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5V5SZVuZoHF",
        "colab_type": "text"
      },
      "source": [
        "## 热身: 用numpy实现两层神经网络\n",
        "一个全连接ReLU神经网络，一个隐藏层，没有bias。用来从x预测y，使用L2 Loss。\n",
        "\n",
        "* $h = W_1X + b_1$\n",
        "* $a = max(0, h)$\n",
        "* $y_{hat} = W_2a + b_2$\n",
        "\n",
        "这一实现完全使用numpy来计算前向神经网络，loss，和反向传播。\n",
        "- forward pass\n",
        "- loss\n",
        "- backward pass\n",
        "\n",
        "numpy ndarray是一个普通的n维array。它不知道任何关于深度学习或者梯度(gradient)的知识，也不知道计算图(computation graph)，只是一种用来计算数学运算的数据结构。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W3-byL3Znm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# N is batch size; D_in is input dimension;\n",
        "# H is hidden dimension; D_out is output dimension.\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "# randomly generate traning data\n",
        "x = np.random.randn(N, D_in)\n",
        "y = np.random.randn(N, D_out)\n",
        "\n",
        "w1 = np.random.randn(D_in, H)\n",
        "w2 = np.random.randn(H, D_out)\n",
        "\n",
        "learning_rate = 1e-6\n",
        "for it in range(500):\n",
        "  #Forward pass\n",
        "  h = x.dot(w1)  # N * H\n",
        "  h_relu = np.maximum(h, 0) # N * H\n",
        "  y_pred = h_relu.dot(w2)   # N * D_out\n",
        "\n",
        "  # compute loss\n",
        "  loss = np.square(y_pred - y).sum()\n",
        "  print(it, loss)\n",
        "\n",
        "  # Backward pass\n",
        "  #compute the gradient\n",
        "  grad_y_pred = 2.0 * (y_pred - y)\n",
        "  grad_w2 = h_relu.T.dot(grad_y_pred)\n",
        "  grad_h_relu = grad_y_pred.dot(w2.T)\n",
        "  grad_h = grad_h_relu.copy()\n",
        "  grad_h[h<0] = 0\n",
        "  grad_w1 = x.T.dot(grad_h)\n",
        "\n",
        "  # update weights of w1 and w2\n",
        "  w1 -= learning_rate * grad_w1\n",
        "  w2 -= learning_rate * grad_w2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6_OAFp-9b3P",
        "colab_type": "text"
      },
      "source": [
        "### PyTorch: Tensors\n",
        "\n",
        "这次我们使用PyTorch tensors来创建前向神经网络，计算损失，以及反向传播。\n",
        "\n",
        "一个PyTorch Tensor很像一个numpy的ndarray。但是它和numpy ndarray最大的区别是，PyTorch Tensor可以在CPU或者GPU上运算。如果想要在GPU上运算，就需要把Tensor换成cuda类型。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzK88Wpf65Gq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ddf5e69f-4d57-4d4a-82cc-ae1754920f76"
      },
      "source": [
        "# N is batch size; D_in is input dimension;\n",
        "# H is hidden dimension; D_out is output dimension.\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "# randomly generate traning data\n",
        "x = torch.randn(N, D_in)\n",
        "y = torch.randn(N, D_out)\n",
        "\n",
        "w1 = torch.randn(D_in, H)\n",
        "w2 = torch.randn(H, D_out)\n",
        "\n",
        "learning_rate = 1e-6\n",
        "for it in range(500):\n",
        "  #Forward pass\n",
        "  h = x.mm(w1)  # N * H\n",
        "  h_relu = h.clamp(min=0) # N * H\n",
        "  y_pred = h_relu.mm(w2)   # N * D_out\n",
        "\n",
        "  # compute loss\n",
        "  loss = (y_pred - y).pow(2).sum().item()\n",
        "  print(it, loss)\n",
        "\n",
        "  # Backward pass\n",
        "  #compute the gradient\n",
        "  grad_y_pred = 2.0 * (y_pred - y)\n",
        "  grad_w2 = h_relu.t().mm(grad_y_pred)\n",
        "  grad_h_relu = grad_y_pred.mm(w2.t())\n",
        "  grad_h = grad_h_relu.clone()\n",
        "  grad_h[h<0] = 0\n",
        "  grad_w1 = x.t().mm(grad_h)\n",
        "\n",
        "  # update weights of w1 and w2\n",
        "  w1 -= learning_rate * grad_w1\n",
        "  w2 -= learning_rate * grad_w2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 37940924.0\n",
            "1 35675340.0\n",
            "2 34338760.0\n",
            "3 28782862.0\n",
            "4 19994012.0\n",
            "5 11567384.0\n",
            "6 6201699.0\n",
            "7 3429428.5\n",
            "8 2123204.75\n",
            "9 1480968.375\n",
            "10 1129841.625\n",
            "11 909993.5625\n",
            "12 755895.5625\n",
            "13 639122.125\n",
            "14 546726.0\n",
            "15 471690.46875\n",
            "16 409633.6875\n",
            "17 357626.125\n",
            "18 313726.71875\n",
            "19 276396.75\n",
            "20 244440.65625\n",
            "21 216987.75\n",
            "22 193254.140625\n",
            "23 172676.921875\n",
            "24 154740.109375\n",
            "25 139015.359375\n",
            "26 125192.5625\n",
            "27 112993.140625\n",
            "28 102185.6875\n",
            "29 92590.03125\n",
            "30 84056.7890625\n",
            "31 76442.6328125\n",
            "32 69626.4609375\n",
            "33 63510.6640625\n",
            "34 58015.04296875\n",
            "35 53064.68359375\n",
            "36 48598.171875\n",
            "37 44564.33203125\n",
            "38 40912.484375\n",
            "39 37597.8984375\n",
            "40 34588.0\n",
            "41 31850.296875\n",
            "42 29353.31640625\n",
            "43 27076.818359375\n",
            "44 24998.853515625\n",
            "45 23101.208984375\n",
            "46 21364.55078125\n",
            "47 19771.865234375\n",
            "48 18311.341796875\n",
            "49 16971.513671875\n",
            "50 15739.810546875\n",
            "51 14606.857421875\n",
            "52 13564.1103515625\n",
            "53 12603.357421875\n",
            "54 11717.4921875\n",
            "55 10903.2490234375\n",
            "56 10153.2021484375\n",
            "57 9460.9912109375\n",
            "58 8821.3076171875\n",
            "59 8228.65625\n",
            "60 7679.5625\n",
            "61 7170.6513671875\n",
            "62 6698.4404296875\n",
            "63 6260.21142578125\n",
            "64 5853.17724609375\n",
            "65 5475.109375\n",
            "66 5123.533203125\n",
            "67 4796.38330078125\n",
            "68 4491.99755859375\n",
            "69 4208.43505859375\n",
            "70 3944.92626953125\n",
            "71 3699.31201171875\n",
            "72 3470.285400390625\n",
            "73 3256.46923828125\n",
            "74 3056.844482421875\n",
            "75 2870.35205078125\n",
            "76 2696.1123046875\n",
            "77 2533.1904296875\n",
            "78 2380.818359375\n",
            "79 2238.3388671875\n",
            "80 2104.956787109375\n",
            "81 1980.0645751953125\n",
            "82 1863.0838623046875\n",
            "83 1753.4268798828125\n",
            "84 1650.693359375\n",
            "85 1554.365234375\n",
            "86 1463.9971923828125\n",
            "87 1379.2689208984375\n",
            "88 1299.6805419921875\n",
            "89 1224.97021484375\n",
            "90 1154.83154296875\n",
            "91 1088.9310302734375\n",
            "92 1027.0086669921875\n",
            "93 968.810546875\n",
            "94 914.0879516601562\n",
            "95 862.6585693359375\n",
            "96 814.2559814453125\n",
            "97 768.730224609375\n",
            "98 725.8780517578125\n",
            "99 685.5410766601562\n",
            "100 647.5570068359375\n",
            "101 611.7881469726562\n",
            "102 578.0950317382812\n",
            "103 546.3463745117188\n",
            "104 516.426513671875\n",
            "105 488.21527099609375\n",
            "106 461.6150207519531\n",
            "107 436.52972412109375\n",
            "108 412.8760070800781\n",
            "109 390.5518798828125\n",
            "110 369.48944091796875\n",
            "111 349.6156921386719\n",
            "112 330.85675048828125\n",
            "113 313.1349182128906\n",
            "114 296.4017639160156\n",
            "115 280.60198974609375\n",
            "116 265.6811218261719\n",
            "117 251.5843963623047\n",
            "118 238.25759887695312\n",
            "119 225.66737365722656\n",
            "120 213.76870727539062\n",
            "121 202.51597595214844\n",
            "122 191.8756561279297\n",
            "123 181.81578063964844\n",
            "124 172.30088806152344\n",
            "125 163.30447387695312\n",
            "126 154.7892608642578\n",
            "127 146.73399353027344\n",
            "128 139.11231994628906\n",
            "129 131.90127563476562\n",
            "130 125.07160949707031\n",
            "131 118.60409545898438\n",
            "132 112.48502349853516\n",
            "133 106.691162109375\n",
            "134 101.20557403564453\n",
            "135 96.00582885742188\n",
            "136 91.08332061767578\n",
            "137 86.42420196533203\n",
            "138 82.00606536865234\n",
            "139 77.8248519897461\n",
            "140 73.86441802978516\n",
            "141 70.11355590820312\n",
            "142 66.55681610107422\n",
            "143 63.18635177612305\n",
            "144 59.991554260253906\n",
            "145 56.96214294433594\n",
            "146 54.089088439941406\n",
            "147 51.36445617675781\n",
            "148 48.78135299682617\n",
            "149 46.33196258544922\n",
            "150 44.005958557128906\n",
            "151 41.8011360168457\n",
            "152 39.70951461791992\n",
            "153 37.726802825927734\n",
            "154 35.842044830322266\n",
            "155 34.05514144897461\n",
            "156 32.35938262939453\n",
            "157 30.74934959411621\n",
            "158 29.222064971923828\n",
            "159 27.771881103515625\n",
            "160 26.394309997558594\n",
            "161 25.088106155395508\n",
            "162 23.84619903564453\n",
            "163 22.667701721191406\n",
            "164 21.548961639404297\n",
            "165 20.48738670349121\n",
            "166 19.478120803833008\n",
            "167 18.51949691772461\n",
            "168 17.60875129699707\n",
            "169 16.744020462036133\n",
            "170 15.922874450683594\n",
            "171 15.141866683959961\n",
            "172 14.401199340820312\n",
            "173 13.696457862854004\n",
            "174 13.02716064453125\n",
            "175 12.390776634216309\n",
            "176 11.786470413208008\n",
            "177 11.212212562561035\n",
            "178 10.665842056274414\n",
            "179 10.146917343139648\n",
            "180 9.653824806213379\n",
            "181 9.184955596923828\n",
            "182 8.739604949951172\n",
            "183 8.315743446350098\n",
            "184 7.9125471115112305\n",
            "185 7.529996871948242\n",
            "186 7.165946960449219\n",
            "187 6.8196258544921875\n",
            "188 6.490172386169434\n",
            "189 6.177272796630859\n",
            "190 5.879278182983398\n",
            "191 5.595887184143066\n",
            "192 5.326756000518799\n",
            "193 5.0705132484436035\n",
            "194 4.826868534088135\n",
            "195 4.594819068908691\n",
            "196 4.374828338623047\n",
            "197 4.164842128753662\n",
            "198 3.965224266052246\n",
            "199 3.77547550201416\n",
            "200 3.5948197841644287\n",
            "201 3.422934055328369\n",
            "202 3.259281873703003\n",
            "203 3.103864908218384\n",
            "204 2.955700159072876\n",
            "205 2.814875602722168\n",
            "206 2.680717945098877\n",
            "207 2.55314040184021\n",
            "208 2.431896209716797\n",
            "209 2.316248655319214\n",
            "210 2.2061314582824707\n",
            "211 2.101325511932373\n",
            "212 2.0016345977783203\n",
            "213 1.9067398309707642\n",
            "214 1.816470742225647\n",
            "215 1.7303472757339478\n",
            "216 1.6485627889633179\n",
            "217 1.5705317258834839\n",
            "218 1.496324062347412\n",
            "219 1.4255590438842773\n",
            "220 1.3583401441574097\n",
            "221 1.2942321300506592\n",
            "222 1.2331727743148804\n",
            "223 1.1751701831817627\n",
            "224 1.119810700416565\n",
            "225 1.0670275688171387\n",
            "226 1.016817569732666\n",
            "227 0.9691089987754822\n",
            "228 0.9235600233078003\n",
            "229 0.8801698684692383\n",
            "230 0.8389105796813965\n",
            "231 0.7994984984397888\n",
            "232 0.7621444463729858\n",
            "233 0.7263635396957397\n",
            "234 0.69232177734375\n",
            "235 0.6599510908126831\n",
            "236 0.6290549635887146\n",
            "237 0.59968501329422\n",
            "238 0.5716457962989807\n",
            "239 0.54497891664505\n",
            "240 0.5195679664611816\n",
            "241 0.49531030654907227\n",
            "242 0.4722943902015686\n",
            "243 0.4502356946468353\n",
            "244 0.42929479479789734\n",
            "245 0.4093296527862549\n",
            "246 0.39026668667793274\n",
            "247 0.3721691966056824\n",
            "248 0.354841023683548\n",
            "249 0.3383483588695526\n",
            "250 0.322662353515625\n",
            "251 0.3076554834842682\n",
            "252 0.29339757561683655\n",
            "253 0.2797408699989319\n",
            "254 0.2668282091617584\n",
            "255 0.2545072138309479\n",
            "256 0.24277476966381073\n",
            "257 0.2314954549074173\n",
            "258 0.22076565027236938\n",
            "259 0.21057893335819244\n",
            "260 0.2008495032787323\n",
            "261 0.19157817959785461\n",
            "262 0.1827700436115265\n",
            "263 0.1743406057357788\n",
            "264 0.16624495387077332\n",
            "265 0.15862354636192322\n",
            "266 0.1513022631406784\n",
            "267 0.14433810114860535\n",
            "268 0.13770006597042084\n",
            "269 0.13137967884540558\n",
            "270 0.12531566619873047\n",
            "271 0.1195807009935379\n",
            "272 0.11411714553833008\n",
            "273 0.10887785255908966\n",
            "274 0.1038726344704628\n",
            "275 0.09911620616912842\n",
            "276 0.0945575088262558\n",
            "277 0.0902474969625473\n",
            "278 0.08610223233699799\n",
            "279 0.082185760140419\n",
            "280 0.07842429727315903\n",
            "281 0.07484623044729233\n",
            "282 0.07141049206256866\n",
            "283 0.06813623011112213\n",
            "284 0.06504929810762405\n",
            "285 0.06206800043582916\n",
            "286 0.059215616434812546\n",
            "287 0.05653227120637894\n",
            "288 0.05396592989563942\n",
            "289 0.051501430571079254\n",
            "290 0.04915908724069595\n",
            "291 0.046910639852285385\n",
            "292 0.04479958489537239\n",
            "293 0.042757075279951096\n",
            "294 0.04083251953125\n",
            "295 0.03897452726960182\n",
            "296 0.037198275327682495\n",
            "297 0.035516075789928436\n",
            "298 0.033899687230587006\n",
            "299 0.03237239643931389\n",
            "300 0.03090246021747589\n",
            "301 0.029486479237675667\n",
            "302 0.028164276853203773\n",
            "303 0.02689414657652378\n",
            "304 0.02567489817738533\n",
            "305 0.024522192776203156\n",
            "306 0.023418566212058067\n",
            "307 0.02236740104854107\n",
            "308 0.021353980526328087\n",
            "309 0.02039393037557602\n",
            "310 0.01948155090212822\n",
            "311 0.018605511635541916\n",
            "312 0.017767809331417084\n",
            "313 0.01697961799800396\n",
            "314 0.016221892088651657\n",
            "315 0.01550780888646841\n",
            "316 0.01481594517827034\n",
            "317 0.01415327936410904\n",
            "318 0.013528555631637573\n",
            "319 0.012926345691084862\n",
            "320 0.012355509214103222\n",
            "321 0.011806002818048\n",
            "322 0.011280114762485027\n",
            "323 0.010790056549012661\n",
            "324 0.010313903912901878\n",
            "325 0.009865228086709976\n",
            "326 0.00943597499281168\n",
            "327 0.009021631442010403\n",
            "328 0.008629318326711655\n",
            "329 0.008256015367805958\n",
            "330 0.00789949856698513\n",
            "331 0.007554592099040747\n",
            "332 0.007220051717013121\n",
            "333 0.0069111124612390995\n",
            "334 0.006614851765334606\n",
            "335 0.00633517699316144\n",
            "336 0.006067063193768263\n",
            "337 0.005803593434393406\n",
            "338 0.005559647921472788\n",
            "339 0.005323012359440327\n",
            "340 0.0050965906120836735\n",
            "341 0.00488278130069375\n",
            "342 0.004676598124206066\n",
            "343 0.00448560481891036\n",
            "344 0.004297223873436451\n",
            "345 0.004117263481020927\n",
            "346 0.003947485703974962\n",
            "347 0.0037905436474829912\n",
            "348 0.0036339007783681154\n",
            "349 0.0034876891877502203\n",
            "350 0.00334270135499537\n",
            "351 0.0032071382738649845\n",
            "352 0.0030782539397478104\n",
            "353 0.002959068864583969\n",
            "354 0.002841188572347164\n",
            "355 0.0027242202777415514\n",
            "356 0.0026174343656748533\n",
            "357 0.0025172436144202948\n",
            "358 0.0024184712674468756\n",
            "359 0.002325901761651039\n",
            "360 0.002236190252006054\n",
            "361 0.002149445004761219\n",
            "362 0.002068390604108572\n",
            "363 0.001987988827750087\n",
            "364 0.001916067791171372\n",
            "365 0.0018440242856740952\n",
            "366 0.0017761281924322248\n",
            "367 0.0017068400047719479\n",
            "368 0.0016493386356160045\n",
            "369 0.0015862826257944107\n",
            "370 0.0015294698532670736\n",
            "371 0.001475535100325942\n",
            "372 0.0014219488948583603\n",
            "373 0.0013713862281292677\n",
            "374 0.0013251653872430325\n",
            "375 0.001277848845347762\n",
            "376 0.0012336918152868748\n",
            "377 0.0011918691452592611\n",
            "378 0.001149502582848072\n",
            "379 0.0011104799341410398\n",
            "380 0.0010725859319791198\n",
            "381 0.001037919195368886\n",
            "382 0.0010034136939793825\n",
            "383 0.0009708369034342468\n",
            "384 0.000940358208026737\n",
            "385 0.0009094069828279316\n",
            "386 0.0008769893902353942\n",
            "387 0.0008511716732755303\n",
            "388 0.0008245608187280595\n",
            "389 0.0007976082852110267\n",
            "390 0.0007723316084593534\n",
            "391 0.0007486914400942624\n",
            "392 0.0007261967402882874\n",
            "393 0.0007028587278909981\n",
            "394 0.0006809025653637946\n",
            "395 0.0006607726099900901\n",
            "396 0.0006407747277989984\n",
            "397 0.0006219285423867404\n",
            "398 0.0006032423698343337\n",
            "399 0.0005864878185093403\n",
            "400 0.0005685852956958115\n",
            "401 0.0005524639273062348\n",
            "402 0.0005371522856876254\n",
            "403 0.0005230028182268143\n",
            "404 0.0005068583996035159\n",
            "405 0.0004925212124362588\n",
            "406 0.00047813067794777453\n",
            "407 0.00046444215695373714\n",
            "408 0.00045142933959141374\n",
            "409 0.0004395277937874198\n",
            "410 0.00042780887451954186\n",
            "411 0.00041623780271038413\n",
            "412 0.0004037944017909467\n",
            "413 0.0003931473765987903\n",
            "414 0.0003821664140559733\n",
            "415 0.00037334641092456877\n",
            "416 0.00036270174314267933\n",
            "417 0.00035377813037484884\n",
            "418 0.0003441830922383815\n",
            "419 0.000335893128067255\n",
            "420 0.0003268670698162168\n",
            "421 0.0003185944224242121\n",
            "422 0.0003103104536421597\n",
            "423 0.00030274823075160384\n",
            "424 0.00029562009149231017\n",
            "425 0.0002878679661080241\n",
            "426 0.0002810755104292184\n",
            "427 0.00027390639297664165\n",
            "428 0.0002669577661436051\n",
            "429 0.0002600724110379815\n",
            "430 0.00025365862529724836\n",
            "431 0.00024804609711281955\n",
            "432 0.00024171672703232616\n",
            "433 0.0002365150285186246\n",
            "434 0.0002305762900505215\n",
            "435 0.00022552521841134876\n",
            "436 0.00022010876273270696\n",
            "437 0.00021626922534778714\n",
            "438 0.0002110338828060776\n",
            "439 0.0002062836429104209\n",
            "440 0.00020154123194515705\n",
            "441 0.00019702255667652935\n",
            "442 0.00019296325626783073\n",
            "443 0.00018861312128137797\n",
            "444 0.00018411404744256288\n",
            "445 0.00018066765915136784\n",
            "446 0.00017696930444799364\n",
            "447 0.000173652297235094\n",
            "448 0.00016948851407505572\n",
            "449 0.00016610536840744317\n",
            "450 0.00016240258992183954\n",
            "451 0.00015934700786601752\n",
            "452 0.0001559284864924848\n",
            "453 0.00015298734069801867\n",
            "454 0.00014948718308005482\n",
            "455 0.0001462406653445214\n",
            "456 0.0001436682214261964\n",
            "457 0.00014033592015039176\n",
            "458 0.00013752399536315352\n",
            "459 0.0001349099911749363\n",
            "460 0.00013247232709545642\n",
            "461 0.0001301121519645676\n",
            "462 0.00012735869677271694\n",
            "463 0.00012491981033235788\n",
            "464 0.00012207556574139744\n",
            "465 0.0001199564358103089\n",
            "466 0.00011751674173865467\n",
            "467 0.00011557964899111539\n",
            "468 0.0001133645127993077\n",
            "469 0.00011112941865576431\n",
            "470 0.00010894046863541007\n",
            "471 0.0001070222569978796\n",
            "472 0.00010559646034380421\n",
            "473 0.00010340373410144821\n",
            "474 0.00010187623411184177\n",
            "475 0.00010007443052018061\n",
            "476 9.8269825684838e-05\n",
            "477 9.64429127634503e-05\n",
            "478 9.492281242273748e-05\n",
            "479 9.314523049397394e-05\n",
            "480 9.149118704954162e-05\n",
            "481 8.990889909910038e-05\n",
            "482 8.805110701359808e-05\n",
            "483 8.660075400257483e-05\n",
            "484 8.527354657417163e-05\n",
            "485 8.372437150683254e-05\n",
            "486 8.244043419836089e-05\n",
            "487 8.103941945591941e-05\n",
            "488 7.971165177877992e-05\n",
            "489 7.820835162419826e-05\n",
            "490 7.715699030086398e-05\n",
            "491 7.596747309435159e-05\n",
            "492 7.450375414919108e-05\n",
            "493 7.315026596188545e-05\n",
            "494 7.200035906862468e-05\n",
            "495 7.098112109815702e-05\n",
            "496 6.987089000176638e-05\n",
            "497 6.864286115160212e-05\n",
            "498 6.791667692596093e-05\n",
            "499 6.683976243948564e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPO5jbPb_qYn",
        "colab_type": "text"
      },
      "source": [
        "Easy to autograd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCjNQLBb_tgX",
        "colab_type": "code",
        "outputId": "33eb9101-3125-450c-f2ab-2ad99d82ad1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "x = torch.tensor(1., requires_grad=True)\n",
        "w = torch.tensor(2., requires_grad=True)\n",
        "b = torch.tensor(3., requires_grad=True)\n",
        "\n",
        "y = w*x + b # y = 2*1 + 3\n",
        "\n",
        "y.backward()\n",
        "\n",
        "# dy / dx = x\n",
        "print(w.grad)\n",
        "print(x.grad)\n",
        "print(b.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.)\n",
            "tensor(2.)\n",
            "tensor(1.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJh2IEIzCSXw",
        "colab_type": "text"
      },
      "source": [
        "### Pytorch: Tensor and autograd\n",
        "\n",
        "One important function of PyTorch is autograd, it can auto derivative all gradient of all parameters\n",
        "\n",
        "One Tensor represents a node in computing graph. If `x` is a Tensor and `x.requires_grad=True`, `x.grad` 是另一个储存着x当前梯度（相当于一个scalar，常常是loss）的向量"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSiyw0hCG6Kb",
        "colab_type": "code",
        "outputId": "232a6012-af43-4aba-8018-9753e13e093a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.randn(N, D_in)\n",
        "y = torch.randn(N, D_out)\n",
        "\n",
        "w1 = torch.randn(D_in, H, requires_grad=True)\n",
        "w2 = torch.randn(H, D_out, requires_grad=True)\n",
        "y_pred = x.mm(w1).clamp(min=0).mm(w2)\n",
        "\n",
        "# compute loss\n",
        "loss = (y_pred - y).pow(2).sum()  # loss is a computation graph\n",
        "print(it, loss)\n",
        "\n",
        "# Backward pass\n",
        "loss.backward()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "499 tensor(28980630., grad_fn=<SumBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKqH4jh6HRhV",
        "colab_type": "code",
        "outputId": "0f272da6-466b-4d7e-90ea-97ae4133ae73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "w1.grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[    43.2615,  14588.2188,  -3502.5093,  ...,    980.6359,\n",
              "          -9134.0400,  -4731.7300],\n",
              "        [ -5573.9766, -18620.1094,  -1356.8555,  ...,  -6540.2686,\n",
              "         -32649.0195, -17386.9609],\n",
              "        [ 35591.2227,  16292.5049,   9043.6992,  ...,  -1564.9768,\n",
              "          33531.2695,  -1500.2920],\n",
              "        ...,\n",
              "        [ -1395.4663,  19331.9160,  -7150.3081,  ...,   -313.4011,\n",
              "          -2732.7993,   1719.4480],\n",
              "        [  1357.8234,   4822.6934,  -1309.7922,  ...,  -6154.7158,\n",
              "          19664.8359,  11898.0098],\n",
              "        [-11014.4873,  -1557.8982,  -4754.4780,  ...,   3842.9922,\n",
              "          -2624.3643, -18650.4023]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKJ4HyzKHYJB",
        "colab_type": "text"
      },
      "source": [
        "Only w1 and w2 have grad, x and y don't have grad"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWeI0xEKCQoa",
        "colab_type": "code",
        "outputId": "c4fd4a07-ebf9-48e5-dd3b-bf2b3bdd9abd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# N is batch size; D_in is input dimension;\n",
        "# H is hidden dimension; D_out is output dimension.\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "# randomly generate traning data\n",
        "x = torch.randn(N, D_in)\n",
        "y = torch.randn(N, D_out)\n",
        "\n",
        "w1 = torch.randn(D_in, H, requires_grad=True)\n",
        "w2 = torch.randn(H, D_out, requires_grad=True)\n",
        "\n",
        "learning_rate = 1e-6\n",
        "for it in range(500):\n",
        "  #Forward pass\n",
        "  y_pred = x.mm(w1).clamp(min=0).mm(w2)\n",
        "\n",
        "  # compute loss\n",
        "  loss = (y_pred - y).pow(2).sum()  # loss is a computation graph\n",
        "  print(it, loss.item())\n",
        "\n",
        "  # Backward pass\n",
        "  loss.backward()\n",
        "\n",
        "  # update weights of w1 and w2\n",
        "  with torch.no_grad(): # save memery, don't save w1.grad and w2.grad\n",
        "    w1 -= learning_rate * w1.grad\n",
        "    w2 -= learning_rate * w2.grad\n",
        "    w1.grad.zero_() # if not, w1.grad will increase one time by one time\n",
        "    w2.grad.zero_() "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 24258520.0\n",
            "1 17556780.0\n",
            "2 15148436.0\n",
            "3 14619362.0\n",
            "4 14745759.0\n",
            "5 14642763.0\n",
            "6 13784261.0\n",
            "7 11982024.0\n",
            "8 9593092.0\n",
            "9 7113953.0\n",
            "10 4996418.0\n",
            "11 3393298.5\n",
            "12 2280177.5\n",
            "13 1544165.875\n",
            "14 1069187.125\n",
            "15 763672.875\n",
            "16 565269.25\n",
            "17 433501.1875\n",
            "18 343503.15625\n",
            "19 279929.625\n",
            "20 233411.734375\n",
            "21 198181.15625\n",
            "22 170690.125\n",
            "23 148596.9375\n",
            "24 130428.578125\n",
            "25 115232.0703125\n",
            "26 102371.8515625\n",
            "27 91319.6796875\n",
            "28 81743.5859375\n",
            "29 73386.2578125\n",
            "30 66054.625\n",
            "31 59587.27734375\n",
            "32 53858.96875\n",
            "33 48776.78125\n",
            "34 44252.48046875\n",
            "35 40212.5078125\n",
            "36 36595.21875\n",
            "37 33347.359375\n",
            "38 30425.978515625\n",
            "39 27794.7265625\n",
            "40 25418.818359375\n",
            "41 23269.365234375\n",
            "42 21323.68359375\n",
            "43 19562.6640625\n",
            "44 17963.8984375\n",
            "45 16510.5\n",
            "46 15187.060546875\n",
            "47 13980.826171875\n",
            "48 12878.6552734375\n",
            "49 11873.0380859375\n",
            "50 10953.84375\n",
            "51 10112.9345703125\n",
            "52 9342.61328125\n",
            "53 8635.9296875\n",
            "54 7987.54931640625\n",
            "55 7391.9140625\n",
            "56 6844.7060546875\n",
            "57 6341.33544921875\n",
            "58 5878.13525390625\n",
            "59 5451.4375\n",
            "60 5057.86083984375\n",
            "61 4694.900390625\n",
            "62 4359.958984375\n",
            "63 4050.615478515625\n",
            "64 3764.673828125\n",
            "65 3500.304931640625\n",
            "66 3255.78515625\n",
            "67 3029.479736328125\n",
            "68 2820.07421875\n",
            "69 2626.15625\n",
            "70 2446.453125\n",
            "71 2279.954833984375\n",
            "72 2125.69482421875\n",
            "73 1982.488525390625\n",
            "74 1849.5517578125\n",
            "75 1726.2049560546875\n",
            "76 1611.64892578125\n",
            "77 1505.1258544921875\n",
            "78 1406.089599609375\n",
            "79 1313.920654296875\n",
            "80 1228.135009765625\n",
            "81 1148.22216796875\n",
            "82 1073.7958984375\n",
            "83 1004.4349365234375\n",
            "84 939.7771606445312\n",
            "85 879.5106201171875\n",
            "86 823.2998046875\n",
            "87 770.8672485351562\n",
            "88 721.9380493164062\n",
            "89 676.2599487304688\n",
            "90 633.6168212890625\n",
            "91 593.7955322265625\n",
            "92 556.5919189453125\n",
            "93 521.82666015625\n",
            "94 489.33660888671875\n",
            "95 458.9540710449219\n",
            "96 430.5491943359375\n",
            "97 403.97808837890625\n",
            "98 379.1191101074219\n",
            "99 355.8622741699219\n",
            "100 334.0907287597656\n",
            "101 313.7099609375\n",
            "102 294.6291809082031\n",
            "103 276.7527160644531\n",
            "104 260.0079040527344\n",
            "105 244.3170623779297\n",
            "106 229.61053466796875\n",
            "107 215.83047485351562\n",
            "108 202.90908813476562\n",
            "109 190.79049682617188\n",
            "110 179.42660522460938\n",
            "111 168.76290893554688\n",
            "112 158.75900268554688\n",
            "113 149.3694610595703\n",
            "114 140.55816650390625\n",
            "115 132.28762817382812\n",
            "116 124.52172088623047\n",
            "117 117.22840118408203\n",
            "118 110.37847137451172\n",
            "119 103.94168090820312\n",
            "120 97.8961181640625\n",
            "121 92.2117919921875\n",
            "122 86.87181854248047\n",
            "123 81.85166931152344\n",
            "124 77.1315689086914\n",
            "125 72.69313049316406\n",
            "126 68.51880645751953\n",
            "127 64.59245300292969\n",
            "128 60.90058135986328\n",
            "129 57.424625396728516\n",
            "130 54.153663635253906\n",
            "131 51.07582092285156\n",
            "132 48.178504943847656\n",
            "133 45.45134353637695\n",
            "134 42.88279724121094\n",
            "135 40.46549987792969\n",
            "136 38.18770980834961\n",
            "137 36.04188537597656\n",
            "138 34.021995544433594\n",
            "139 32.11746597290039\n",
            "140 30.322952270507812\n",
            "141 28.632205963134766\n",
            "142 27.03828239440918\n",
            "143 25.535797119140625\n",
            "144 24.119348526000977\n",
            "145 22.784008026123047\n",
            "146 21.524444580078125\n",
            "147 20.337329864501953\n",
            "148 19.21611213684082\n",
            "149 18.15947914123535\n",
            "150 17.1628360748291\n",
            "151 16.222326278686523\n",
            "152 15.334861755371094\n",
            "153 14.496630668640137\n",
            "154 13.705928802490234\n",
            "155 12.959726333618164\n",
            "156 12.254531860351562\n",
            "157 11.589400291442871\n",
            "158 10.961408615112305\n",
            "159 10.368293762207031\n",
            "160 9.8078031539917\n",
            "161 9.27890682220459\n",
            "162 8.778961181640625\n",
            "163 8.306703567504883\n",
            "164 7.8606367111206055\n",
            "165 7.4389967918396\n",
            "166 7.040698051452637\n",
            "167 6.663900375366211\n",
            "168 6.308338642120361\n",
            "169 5.971708297729492\n",
            "170 5.653787612915039\n",
            "171 5.353281497955322\n",
            "172 5.068795204162598\n",
            "173 4.799971580505371\n",
            "174 4.545670986175537\n",
            "175 4.305476188659668\n",
            "176 4.077941417694092\n",
            "177 3.862905740737915\n",
            "178 3.659514904022217\n",
            "179 3.4669811725616455\n",
            "180 3.2846386432647705\n",
            "181 3.112229585647583\n",
            "182 2.9493534564971924\n",
            "183 2.7951395511627197\n",
            "184 2.6490654945373535\n",
            "185 2.510578155517578\n",
            "186 2.379627227783203\n",
            "187 2.255831718444824\n",
            "188 2.138395309448242\n",
            "189 2.0273799896240234\n",
            "190 1.922136664390564\n",
            "191 1.822596788406372\n",
            "192 1.7283060550689697\n",
            "193 1.6390421390533447\n",
            "194 1.5544062852859497\n",
            "195 1.4742940664291382\n",
            "196 1.3982566595077515\n",
            "197 1.3261797428131104\n",
            "198 1.2581188678741455\n",
            "199 1.1935291290283203\n",
            "200 1.132370114326477\n",
            "201 1.0743408203125\n",
            "202 1.0193434953689575\n",
            "203 0.9672355055809021\n",
            "204 0.9178758859634399\n",
            "205 0.8711276650428772\n",
            "206 0.8267077207565308\n",
            "207 0.7845892310142517\n",
            "208 0.7447463870048523\n",
            "209 0.7069569230079651\n",
            "210 0.6710368394851685\n",
            "211 0.6370313167572021\n",
            "212 0.6047447919845581\n",
            "213 0.5741649270057678\n",
            "214 0.5452204346656799\n",
            "215 0.5177666544914246\n",
            "216 0.4916149079799652\n",
            "217 0.46682900190353394\n",
            "218 0.44336777925491333\n",
            "219 0.4211120009422302\n",
            "220 0.4000031352043152\n",
            "221 0.37987303733825684\n",
            "222 0.36087533831596375\n",
            "223 0.34284573793411255\n",
            "224 0.32568252086639404\n",
            "225 0.3094305694103241\n",
            "226 0.29399845004081726\n",
            "227 0.27937206625938416\n",
            "228 0.2654576897621155\n",
            "229 0.2522570490837097\n",
            "230 0.23969587683677673\n",
            "231 0.2277778685092926\n",
            "232 0.2164909690618515\n",
            "233 0.2057405710220337\n",
            "234 0.19559380412101746\n",
            "235 0.18588343262672424\n",
            "236 0.1766878068447113\n",
            "237 0.16797217726707458\n",
            "238 0.1597069650888443\n",
            "239 0.1518278867006302\n",
            "240 0.14433345198631287\n",
            "241 0.1372242569923401\n",
            "242 0.13049203157424927\n",
            "243 0.124083511531353\n",
            "244 0.11801654100418091\n",
            "245 0.11223176121711731\n",
            "246 0.1067616418004036\n",
            "247 0.10151756554841995\n",
            "248 0.0965498834848404\n",
            "249 0.09186253696680069\n",
            "250 0.08735482394695282\n",
            "251 0.083085797727108\n",
            "252 0.07906574755907059\n",
            "253 0.07520466297864914\n",
            "254 0.07154551148414612\n",
            "255 0.06805279850959778\n",
            "256 0.06477070599794388\n",
            "257 0.06162020191550255\n",
            "258 0.058634202927351\n",
            "259 0.05581104755401611\n",
            "260 0.05312124639749527\n",
            "261 0.05055467411875725\n",
            "262 0.04811632260680199\n",
            "263 0.04579853266477585\n",
            "264 0.043592408299446106\n",
            "265 0.04149213433265686\n",
            "266 0.03950822725892067\n",
            "267 0.03759186714887619\n",
            "268 0.03579771891236305\n",
            "269 0.034091755747795105\n",
            "270 0.03244611993432045\n",
            "271 0.030897781252861023\n",
            "272 0.029435157775878906\n",
            "273 0.028034284710884094\n",
            "274 0.02668927237391472\n",
            "275 0.025425879284739494\n",
            "276 0.02421725168824196\n",
            "277 0.02306370437145233\n",
            "278 0.021978165954351425\n",
            "279 0.02095600962638855\n",
            "280 0.019953066483139992\n",
            "281 0.019013145938515663\n",
            "282 0.018119869753718376\n",
            "283 0.01727176271378994\n",
            "284 0.016453489661216736\n",
            "285 0.015691988170146942\n",
            "286 0.014949765987694263\n",
            "287 0.014249300584197044\n",
            "288 0.01359809935092926\n",
            "289 0.012958100996911526\n",
            "290 0.0123433293774724\n",
            "291 0.01177559420466423\n",
            "292 0.01122900191694498\n",
            "293 0.010714623145759106\n",
            "294 0.01023059245198965\n",
            "295 0.009757004678249359\n",
            "296 0.009306026622653008\n",
            "297 0.008882325142621994\n",
            "298 0.008477641269564629\n",
            "299 0.008091457188129425\n",
            "300 0.007723040878772736\n",
            "301 0.007376650348305702\n",
            "302 0.007039778865873814\n",
            "303 0.00672610430046916\n",
            "304 0.006424148101359606\n",
            "305 0.0061355470679700375\n",
            "306 0.005857768934220076\n",
            "307 0.005595446098595858\n",
            "308 0.00535289291292429\n",
            "309 0.00511478167027235\n",
            "310 0.004888358525931835\n",
            "311 0.004675618372857571\n",
            "312 0.004472545348107815\n",
            "313 0.0042766183614730835\n",
            "314 0.004090697038918734\n",
            "315 0.003912512678653002\n",
            "316 0.0037493500858545303\n",
            "317 0.00359141593798995\n",
            "318 0.003439477412030101\n",
            "319 0.003293360350653529\n",
            "320 0.003153415396809578\n",
            "321 0.0030197894666343927\n",
            "322 0.002893009688705206\n",
            "323 0.002775756875053048\n",
            "324 0.0026635490357875824\n",
            "325 0.002550085075199604\n",
            "326 0.0024454807862639427\n",
            "327 0.002348042791709304\n",
            "328 0.002255006693303585\n",
            "329 0.002163153374567628\n",
            "330 0.0020752563141286373\n",
            "331 0.001990312710404396\n",
            "332 0.0019126771949231625\n",
            "333 0.0018395446240901947\n",
            "334 0.0017673769034445286\n",
            "335 0.0016996675403788686\n",
            "336 0.0016329000936821103\n",
            "337 0.0015699667856097221\n",
            "338 0.0015112515538930893\n",
            "339 0.0014552564825862646\n",
            "340 0.001398821477778256\n",
            "341 0.0013477508910000324\n",
            "342 0.0012993301497772336\n",
            "343 0.0012509721564128995\n",
            "344 0.0012050047516822815\n",
            "345 0.0011618845164775848\n",
            "346 0.0011174902319908142\n",
            "347 0.0010782619938254356\n",
            "348 0.0010401380714029074\n",
            "349 0.0010036855237558484\n",
            "350 0.0009672940359450877\n",
            "351 0.0009350209729745984\n",
            "352 0.0009023626334965229\n",
            "353 0.0008723463397473097\n",
            "354 0.0008431405876763165\n",
            "355 0.0008145683677867055\n",
            "356 0.0007870548870414495\n",
            "357 0.0007613446796312928\n",
            "358 0.000736367714125663\n",
            "359 0.0007128361612558365\n",
            "360 0.0006882095476612449\n",
            "361 0.0006678052013739944\n",
            "362 0.0006456067785620689\n",
            "363 0.0006254172185435891\n",
            "364 0.0006058894796296954\n",
            "365 0.0005862105754204094\n",
            "366 0.0005693301209248602\n",
            "367 0.0005508176400326192\n",
            "368 0.0005341243813745677\n",
            "369 0.0005172509117983282\n",
            "370 0.0005011798348277807\n",
            "371 0.00048650390817783773\n",
            "372 0.0004717915435321629\n",
            "373 0.0004578793596010655\n",
            "374 0.0004454595036804676\n",
            "375 0.00043199106585234404\n",
            "376 0.00041940968367271125\n",
            "377 0.00040746183367446065\n",
            "378 0.0003953105479013175\n",
            "379 0.00038444227539002895\n",
            "380 0.0003732415207196027\n",
            "381 0.00036337520577944815\n",
            "382 0.00035307148937135935\n",
            "383 0.0003430857905186713\n",
            "384 0.0003341463743709028\n",
            "385 0.00032552710035815835\n",
            "386 0.0003167334070894867\n",
            "387 0.0003081382892560214\n",
            "388 0.0003009651554748416\n",
            "389 0.0002932082861661911\n",
            "390 0.00028559297788888216\n",
            "391 0.0002780173090286553\n",
            "392 0.00027086096815764904\n",
            "393 0.0002639559970702976\n",
            "394 0.0002573283272795379\n",
            "395 0.00025067341630347073\n",
            "396 0.00024463041336275637\n",
            "397 0.00023814559972379357\n",
            "398 0.00023241729650180787\n",
            "399 0.00022702512796968222\n",
            "400 0.00022132103913463652\n",
            "401 0.00021613863646052778\n",
            "402 0.0002111859794240445\n",
            "403 0.00020604653400368989\n",
            "404 0.00020191696239635348\n",
            "405 0.00019698248070199043\n",
            "406 0.0001923553936649114\n",
            "407 0.00018814935174304992\n",
            "408 0.00018328077567275614\n",
            "409 0.00017878483049571514\n",
            "410 0.00017534467042423785\n",
            "411 0.00017213598766829818\n",
            "412 0.00016785645857453346\n",
            "413 0.00016382106696255505\n",
            "414 0.00016006050282157958\n",
            "415 0.0001562188845127821\n",
            "416 0.00015312984760385007\n",
            "417 0.0001500272483099252\n",
            "418 0.00014671034296043217\n",
            "419 0.00014327956887427717\n",
            "420 0.0001405673974659294\n",
            "421 0.00013745813339482993\n",
            "422 0.00013473725994117558\n",
            "423 0.00013228337047621608\n",
            "424 0.00012929795775562525\n",
            "425 0.00012630228593479842\n",
            "426 0.0001239111734321341\n",
            "427 0.00012149910617154092\n",
            "428 0.0001191636620205827\n",
            "429 0.00011728643585229293\n",
            "430 0.00011472783808130771\n",
            "431 0.00011255592107772827\n",
            "432 0.00011055960203520954\n",
            "433 0.00010823947377502918\n",
            "434 0.00010602356633171439\n",
            "435 0.00010407930676592514\n",
            "436 0.00010204335558228195\n",
            "437 0.00010027016833191738\n",
            "438 9.839076665230095e-05\n",
            "439 9.647301340010017e-05\n",
            "440 9.491948003415018e-05\n",
            "441 9.336922084912658e-05\n",
            "442 9.161883644992486e-05\n",
            "443 9.043398313224316e-05\n",
            "444 8.855368650984019e-05\n",
            "445 8.722337952349335e-05\n",
            "446 8.575509855290875e-05\n",
            "447 8.436145435553044e-05\n",
            "448 8.273683488368988e-05\n",
            "449 8.123081352096051e-05\n",
            "450 7.991426537046209e-05\n",
            "451 7.857575837988406e-05\n",
            "452 7.743784954072908e-05\n",
            "453 7.631102198502049e-05\n",
            "454 7.533213647548109e-05\n",
            "455 7.413249113596976e-05\n",
            "456 7.248007750604302e-05\n",
            "457 7.167045259848237e-05\n",
            "458 7.053662557154894e-05\n",
            "459 6.956839933991432e-05\n",
            "460 6.81632081978023e-05\n",
            "461 6.714058690704405e-05\n",
            "462 6.627998664043844e-05\n",
            "463 6.532854604301974e-05\n",
            "464 6.416762334993109e-05\n",
            "465 6.315719656413421e-05\n",
            "466 6.249564466997981e-05\n",
            "467 6.176142778713256e-05\n",
            "468 6.065747584216297e-05\n",
            "469 5.98686674493365e-05\n",
            "470 5.9280660934746265e-05\n",
            "471 5.843707549502142e-05\n",
            "472 5.796034020022489e-05\n",
            "473 5.6950997532112524e-05\n",
            "474 5.6118871725630015e-05\n",
            "475 5.523547588381916e-05\n",
            "476 5.438796506496146e-05\n",
            "477 5.353696542442776e-05\n",
            "478 5.2890096412738785e-05\n",
            "479 5.225000495556742e-05\n",
            "480 5.165448965271935e-05\n",
            "481 5.084539589006454e-05\n",
            "482 5.002011312171817e-05\n",
            "483 4.936162440571934e-05\n",
            "484 4.868149699177593e-05\n",
            "485 4.810885729966685e-05\n",
            "486 4.781616007676348e-05\n",
            "487 4.714684473583475e-05\n",
            "488 4.6422603190876544e-05\n",
            "489 4.566861753119156e-05\n",
            "490 4.531125523499213e-05\n",
            "491 4.455669841263443e-05\n",
            "492 4.407478263601661e-05\n",
            "493 4.349796654423699e-05\n",
            "494 4.285202521714382e-05\n",
            "495 4.2352094169473276e-05\n",
            "496 4.180253017693758e-05\n",
            "497 4.1417071770410985e-05\n",
            "498 4.0713566704653203e-05\n",
            "499 4.028204784845002e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePO859_nHwBM",
        "colab_type": "text"
      },
      "source": [
        "### Pytorch: nn\n",
        "\n",
        "这次我们使用Pytorch中的nn这个库来构造网络。用Pytorch autograd来构造计算图和计算gradient，然后pytorch会帮我们自动计算gradient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2xbceWRIJYw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d9b694a3-cee6-43b3-9ddf-0d28c0c87f6b"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# N is batch size; D_in is input dimension;\n",
        "# H is hidden dimension; D_out is output dimension.\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "# randomly generate traning data\n",
        "x = torch.randn(N, D_in)\n",
        "y = torch.randn(N, D_out)\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(D_in, H, bias=False),  # w1 * x + b\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(H, D_out)\n",
        ")\n",
        "\n",
        "#model = model.cuda()\n",
        "torch.nn.init.normal_(model[0].weight)  # parameter change to normal distribution to get better results\n",
        "torch.nn.init.normal_(model[2].weight)\n",
        "\n",
        "loss_fn = nn.MSELoss(reduction='sum')\n",
        "\n",
        "learning_rate = 1e-6\n",
        "for it in range(500):\n",
        "  #Forward pass\n",
        "  y_pred = model(x)  # model.forward()\n",
        "\n",
        "  # compute loss\n",
        "  loss = loss_fn(y_pred, y)  # loss is a computation graph\n",
        "  print(it, loss.item())\n",
        "\n",
        "\n",
        "\n",
        "  # Backward pass\n",
        "  loss.backward()\n",
        "\n",
        "  # update weights of w1 and w2\n",
        "  with torch.no_grad(): # save memery, don't save w1.grad and w2.grad\n",
        "    for param in model.parameters():  # param (tensor, grad)\n",
        "      param -= learning_rate * param.grad  # goal is minus grad from \n",
        "  model.zero_grad()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 32281040.0\n",
            "1 30272180.0\n",
            "2 30909016.0\n",
            "3 29217332.0\n",
            "4 23486102.0\n",
            "5 15600402.0\n",
            "6 8979930.0\n",
            "7 4884352.5\n",
            "8 2769176.0\n",
            "9 1729936.625\n",
            "10 1202640.125\n",
            "11 909722.5\n",
            "12 727884.75\n",
            "13 602774.375\n",
            "14 509558.5625\n",
            "15 436360.8125\n",
            "16 376883.6875\n",
            "17 327587.21875\n",
            "18 286138.59375\n",
            "19 250922.875\n",
            "20 220814.515625\n",
            "21 194960.953125\n",
            "22 172631.859375\n",
            "23 153274.015625\n",
            "24 136429.359375\n",
            "25 121737.046875\n",
            "26 108874.859375\n",
            "27 97577.265625\n",
            "28 87615.46875\n",
            "29 78824.90625\n",
            "30 71043.078125\n",
            "31 64129.078125\n",
            "32 57977.84765625\n",
            "33 52492.05859375\n",
            "34 47593.33984375\n",
            "35 43208.33203125\n",
            "36 39273.19140625\n",
            "37 35738.00390625\n",
            "38 32556.74609375\n",
            "39 29688.998046875\n",
            "40 27101.224609375\n",
            "41 24763.828125\n",
            "42 22648.548828125\n",
            "43 20732.099609375\n",
            "44 18993.662109375\n",
            "45 17414.900390625\n",
            "46 15979.9892578125\n",
            "47 14674.2685546875\n",
            "48 13484.6298828125\n",
            "49 12399.7236328125\n",
            "50 11409.9599609375\n",
            "51 10505.908203125\n",
            "52 9679.75390625\n",
            "53 8923.6611328125\n",
            "54 8231.2763671875\n",
            "55 7597.00244140625\n",
            "56 7015.48095703125\n",
            "57 6481.9658203125\n",
            "58 5992.10498046875\n",
            "59 5542.0732421875\n",
            "60 5128.37939453125\n",
            "61 4747.80078125\n",
            "62 4397.5859375\n",
            "63 4075.081298828125\n",
            "64 3777.79541015625\n",
            "65 3503.64453125\n",
            "66 3250.709716796875\n",
            "67 3017.259765625\n",
            "68 2801.667236328125\n",
            "69 2602.44580078125\n",
            "70 2418.338134765625\n",
            "71 2248.11474609375\n",
            "72 2090.58740234375\n",
            "73 1944.78955078125\n",
            "74 1809.7847900390625\n",
            "75 1684.73291015625\n",
            "76 1568.78369140625\n",
            "77 1461.3170166015625\n",
            "78 1361.6265869140625\n",
            "79 1269.1328125\n",
            "80 1183.262939453125\n",
            "81 1103.542724609375\n",
            "82 1029.4793701171875\n",
            "83 960.6558837890625\n",
            "84 896.7058715820312\n",
            "85 837.2123413085938\n",
            "86 781.9013061523438\n",
            "87 730.4155883789062\n",
            "88 682.506103515625\n",
            "89 637.8737182617188\n",
            "90 596.3348388671875\n",
            "91 557.6255493164062\n",
            "92 521.5458984375\n",
            "93 487.9322204589844\n",
            "94 456.57550048828125\n",
            "95 427.32586669921875\n",
            "96 400.0433349609375\n",
            "97 374.5873107910156\n",
            "98 350.82965087890625\n",
            "99 328.6500549316406\n",
            "100 307.9295349121094\n",
            "101 288.574462890625\n",
            "102 270.4920654296875\n",
            "103 253.59048461914062\n",
            "104 237.79730224609375\n",
            "105 223.0255584716797\n",
            "106 209.21348571777344\n",
            "107 196.29229736328125\n",
            "108 184.201904296875\n",
            "109 172.88589477539062\n",
            "110 162.293212890625\n",
            "111 152.3787078857422\n",
            "112 143.09259033203125\n",
            "113 134.3946990966797\n",
            "114 126.24607849121094\n",
            "115 118.61351776123047\n",
            "116 111.4619369506836\n",
            "117 104.75609588623047\n",
            "118 98.46580505371094\n",
            "119 92.56996154785156\n",
            "120 87.0394058227539\n",
            "121 81.85363006591797\n",
            "122 76.98707580566406\n",
            "123 72.4201431274414\n",
            "124 68.13404846191406\n",
            "125 64.11088562011719\n",
            "126 60.333282470703125\n",
            "127 56.7846565246582\n",
            "128 53.454097747802734\n",
            "129 50.32412338256836\n",
            "130 47.38405990600586\n",
            "131 44.6229248046875\n",
            "132 42.026607513427734\n",
            "133 39.586090087890625\n",
            "134 37.29273223876953\n",
            "135 35.13676071166992\n",
            "136 33.11016845703125\n",
            "137 31.203004837036133\n",
            "138 29.409473419189453\n",
            "139 27.722171783447266\n",
            "140 26.134780883789062\n",
            "141 24.641212463378906\n",
            "142 23.230485916137695\n",
            "143 21.904691696166992\n",
            "144 20.655807495117188\n",
            "145 19.481325149536133\n",
            "146 18.37530517578125\n",
            "147 17.333740234375\n",
            "148 16.353588104248047\n",
            "149 15.430582046508789\n",
            "150 14.561040878295898\n",
            "151 13.741912841796875\n",
            "152 12.970019340515137\n",
            "153 12.24305534362793\n",
            "154 11.55760383605957\n",
            "155 10.91193675994873\n",
            "156 10.303614616394043\n",
            "157 9.729284286499023\n",
            "158 9.188776969909668\n",
            "159 8.678582191467285\n",
            "160 8.197468757629395\n",
            "161 7.743584632873535\n",
            "162 7.315799236297607\n",
            "163 6.9121809005737305\n",
            "164 6.531529426574707\n",
            "165 6.1724138259887695\n",
            "166 5.833187580108643\n",
            "167 5.513388156890869\n",
            "168 5.2117133140563965\n",
            "169 4.92657995223999\n",
            "170 4.657299041748047\n",
            "171 4.403483867645264\n",
            "172 4.1638970375061035\n",
            "173 3.9372997283935547\n",
            "174 3.7234225273132324\n",
            "175 3.521421432495117\n",
            "176 3.330665349960327\n",
            "177 3.1505799293518066\n",
            "178 2.9801602363586426\n",
            "179 2.819509983062744\n",
            "180 2.6675052642822266\n",
            "181 2.5240111351013184\n",
            "182 2.3881711959838867\n",
            "183 2.2600841522216797\n",
            "184 2.1388919353485107\n",
            "185 2.0243022441864014\n",
            "186 1.9160704612731934\n",
            "187 1.8136019706726074\n",
            "188 1.7167932987213135\n",
            "189 1.6253063678741455\n",
            "190 1.538867712020874\n",
            "191 1.4568719863891602\n",
            "192 1.3795700073242188\n",
            "193 1.306253433227539\n",
            "194 1.2371525764465332\n",
            "195 1.1715507507324219\n",
            "196 1.1095356941223145\n",
            "197 1.0509495735168457\n",
            "198 0.9954631924629211\n",
            "199 0.9429075717926025\n",
            "200 0.8932374715805054\n",
            "201 0.8462777137756348\n",
            "202 0.801785945892334\n",
            "203 0.7596091032028198\n",
            "204 0.7197322845458984\n",
            "205 0.6819729804992676\n",
            "206 0.6462786197662354\n",
            "207 0.6124991774559021\n",
            "208 0.5804146528244019\n",
            "209 0.5500804781913757\n",
            "210 0.5213708281517029\n",
            "211 0.49421703815460205\n",
            "212 0.46843117475509644\n",
            "213 0.4440470337867737\n",
            "214 0.4209534227848053\n",
            "215 0.3991798460483551\n",
            "216 0.37840408086776733\n",
            "217 0.358777791261673\n",
            "218 0.34014400839805603\n",
            "219 0.3225121796131134\n",
            "220 0.3058199882507324\n",
            "221 0.2900121510028839\n",
            "222 0.2750585973262787\n",
            "223 0.2608456611633301\n",
            "224 0.24740943312644958\n",
            "225 0.23468105494976044\n",
            "226 0.22254928946495056\n",
            "227 0.21110960841178894\n",
            "228 0.2002771496772766\n",
            "229 0.18996210396289825\n",
            "230 0.1801973432302475\n",
            "231 0.1709538698196411\n",
            "232 0.1621774286031723\n",
            "233 0.15382692217826843\n",
            "234 0.14596740901470184\n",
            "235 0.1384868621826172\n",
            "236 0.1314152181148529\n",
            "237 0.12469667196273804\n",
            "238 0.11831995844841003\n",
            "239 0.1122879609465599\n",
            "240 0.10657374560832977\n",
            "241 0.10110703110694885\n",
            "242 0.09599224478006363\n",
            "243 0.09114503115415573\n",
            "244 0.08646396547555923\n",
            "245 0.08207520842552185\n",
            "246 0.0778978168964386\n",
            "247 0.07394085824489594\n",
            "248 0.07020539045333862\n",
            "249 0.06661544740200043\n",
            "250 0.06324451416730881\n",
            "251 0.06004824861884117\n",
            "252 0.0570092499256134\n",
            "253 0.05411764606833458\n",
            "254 0.05138760805130005\n",
            "255 0.04881047457456589\n",
            "256 0.04633773863315582\n",
            "257 0.04400992393493652\n",
            "258 0.041795581579208374\n",
            "259 0.03968551754951477\n",
            "260 0.037703678011894226\n",
            "261 0.03580180183053017\n",
            "262 0.033998310565948486\n",
            "263 0.03230459243059158\n",
            "264 0.03068145364522934\n",
            "265 0.029146045446395874\n",
            "266 0.02768862619996071\n",
            "267 0.026296157389879227\n",
            "268 0.024980612099170685\n",
            "269 0.023731879889965057\n",
            "270 0.022544777020812035\n",
            "271 0.02143171988427639\n",
            "272 0.020360102877020836\n",
            "273 0.019350314512848854\n",
            "274 0.018386241048574448\n",
            "275 0.01747775822877884\n",
            "276 0.016600387170910835\n",
            "277 0.01577642746269703\n",
            "278 0.015005710534751415\n",
            "279 0.014254791662096977\n",
            "280 0.01354955229908228\n",
            "281 0.012876270338892937\n",
            "282 0.01224803552031517\n",
            "283 0.011645365506410599\n",
            "284 0.011072015389800072\n",
            "285 0.010535608045756817\n",
            "286 0.010025394149124622\n",
            "287 0.009535184130072594\n",
            "288 0.009081091731786728\n",
            "289 0.00863827858120203\n",
            "290 0.008220873773097992\n",
            "291 0.007822250947356224\n",
            "292 0.007445110008120537\n",
            "293 0.007087654434144497\n",
            "294 0.006749541033059359\n",
            "295 0.006426975131034851\n",
            "296 0.006119583733379841\n",
            "297 0.0058302730321884155\n",
            "298 0.00555433239787817\n",
            "299 0.0052925823256373405\n",
            "300 0.005043462384492159\n",
            "301 0.004806488752365112\n",
            "302 0.004580710083246231\n",
            "303 0.004370436072349548\n",
            "304 0.004165565129369497\n",
            "305 0.003974268212914467\n",
            "306 0.0037917010486125946\n",
            "307 0.0036179241724312305\n",
            "308 0.003452128265053034\n",
            "309 0.0032918103970587254\n",
            "310 0.0031456623692065477\n",
            "311 0.0030017257668077946\n",
            "312 0.0028680518735200167\n",
            "313 0.002742030890658498\n",
            "314 0.0026204439345747232\n",
            "315 0.0025039201136678457\n",
            "316 0.0023938885424286127\n",
            "317 0.0022886658553034067\n",
            "318 0.002191322622820735\n",
            "319 0.002098227385431528\n",
            "320 0.0020061268005520105\n",
            "321 0.0019190239254385233\n",
            "322 0.001839655451476574\n",
            "323 0.0017596755642443895\n",
            "324 0.0016845159698277712\n",
            "325 0.0016150819137692451\n",
            "326 0.0015474134124815464\n",
            "327 0.0014850026927888393\n",
            "328 0.0014232491375878453\n",
            "329 0.0013666934100911021\n",
            "330 0.0013125751866027713\n",
            "331 0.0012576011940836906\n",
            "332 0.0012083833571523428\n",
            "333 0.0011614500544965267\n",
            "334 0.0011160899884998798\n",
            "335 0.0010714096715673804\n",
            "336 0.0010302052833139896\n",
            "337 0.000991610810160637\n",
            "338 0.0009528795490041375\n",
            "339 0.0009169950499199331\n",
            "340 0.0008821572409942746\n",
            "341 0.0008498557144775987\n",
            "342 0.0008186209597624838\n",
            "343 0.0007880177581682801\n",
            "344 0.0007597211515530944\n",
            "345 0.0007312333909794688\n",
            "346 0.0007046611281111836\n",
            "347 0.0006798622198402882\n",
            "348 0.0006557551678270102\n",
            "349 0.0006321391556411982\n",
            "350 0.0006094150012359023\n",
            "351 0.0005888099549338222\n",
            "352 0.0005665632779709995\n",
            "353 0.0005482204724103212\n",
            "354 0.0005293590947985649\n",
            "355 0.0005115768290124834\n",
            "356 0.000494090374559164\n",
            "357 0.0004781321040354669\n",
            "358 0.0004621722036972642\n",
            "359 0.0004471071297302842\n",
            "360 0.0004324633628129959\n",
            "361 0.00041919448995031416\n",
            "362 0.0004055686295032501\n",
            "363 0.00039295098395086825\n",
            "364 0.0003809703921433538\n",
            "365 0.0003698491200339049\n",
            "366 0.00035799044417217374\n",
            "367 0.000347194611094892\n",
            "368 0.00033630101825110614\n",
            "369 0.0003264804545324296\n",
            "370 0.00031648288131691515\n",
            "371 0.0003069759695790708\n",
            "372 0.0002978484844788909\n",
            "373 0.0002888556045945734\n",
            "374 0.0002805039403028786\n",
            "375 0.00027290458092465997\n",
            "376 0.0002645444474183023\n",
            "377 0.0002572902594693005\n",
            "378 0.00025027384981513023\n",
            "379 0.00024245501845143735\n",
            "380 0.00023572644568048418\n",
            "381 0.00022968203120399266\n",
            "382 0.00022357147827278823\n",
            "383 0.0002178064314648509\n",
            "384 0.00021212056162767112\n",
            "385 0.00020645315817091614\n",
            "386 0.00020081977709196508\n",
            "387 0.000195884465938434\n",
            "388 0.00019061799685005099\n",
            "389 0.0001861129276221618\n",
            "390 0.00018099827866535634\n",
            "391 0.00017636449774727225\n",
            "392 0.00017223246686626226\n",
            "393 0.00016789164510555565\n",
            "394 0.00016398224397562444\n",
            "395 0.0001598903036210686\n",
            "396 0.0001557789510115981\n",
            "397 0.0001520104124210775\n",
            "398 0.0001485854882048443\n",
            "399 0.0001453418080927804\n",
            "400 0.00014194948016665876\n",
            "401 0.0001387831143802032\n",
            "402 0.0001356395659968257\n",
            "403 0.00013269030023366213\n",
            "404 0.0001294442336075008\n",
            "405 0.00012640896602533758\n",
            "406 0.00012367934687063098\n",
            "407 0.00012102215987397358\n",
            "408 0.00011841426021419466\n",
            "409 0.00011563519365154207\n",
            "410 0.00011287427332717925\n",
            "411 0.00011062365956604481\n",
            "412 0.00010801779717439786\n",
            "413 0.00010547776037128642\n",
            "414 0.000103383106761612\n",
            "415 0.00010113111056853086\n",
            "416 9.87163875834085e-05\n",
            "417 9.70248511293903e-05\n",
            "418 9.516002319287509e-05\n",
            "419 9.319100354332477e-05\n",
            "420 9.126856457442045e-05\n",
            "421 8.928548049880192e-05\n",
            "422 8.755942690186203e-05\n",
            "423 8.583220915170386e-05\n",
            "424 8.413896284764633e-05\n",
            "425 8.242880721809343e-05\n",
            "426 8.071523916441947e-05\n",
            "427 7.886810635682195e-05\n",
            "428 7.743089372524992e-05\n",
            "429 7.584468403365463e-05\n",
            "430 7.464486407116055e-05\n",
            "431 7.318409188883379e-05\n",
            "432 7.18855662853457e-05\n",
            "433 7.060972711769864e-05\n",
            "434 6.925206980668008e-05\n",
            "435 6.811053026467562e-05\n",
            "436 6.690518785035238e-05\n",
            "437 6.552909326273948e-05\n",
            "438 6.437337287934497e-05\n",
            "439 6.330983887892216e-05\n",
            "440 6.210360152181238e-05\n",
            "441 6.0891710745636374e-05\n",
            "442 5.950102786300704e-05\n",
            "443 5.896624134038575e-05\n",
            "444 5.767231778008863e-05\n",
            "445 5.68739342270419e-05\n",
            "446 5.593564492301084e-05\n",
            "447 5.485789733938873e-05\n",
            "448 5.421175592346117e-05\n",
            "449 5.324686208041385e-05\n",
            "450 5.242295446805656e-05\n",
            "451 5.1710085244849324e-05\n",
            "452 5.096620589029044e-05\n",
            "453 5.017327202949673e-05\n",
            "454 4.93402621941641e-05\n",
            "455 4.878460822510533e-05\n",
            "456 4.785903001902625e-05\n",
            "457 4.720456126960926e-05\n",
            "458 4.630938929039985e-05\n",
            "459 4.548704600892961e-05\n",
            "460 4.486810212256387e-05\n",
            "461 4.417981472215615e-05\n",
            "462 4.34937646787148e-05\n",
            "463 4.293425445212051e-05\n",
            "464 4.228595207678154e-05\n",
            "465 4.172732224105857e-05\n",
            "466 4.132084723096341e-05\n",
            "467 4.061734216520563e-05\n",
            "468 3.968790770159103e-05\n",
            "469 3.934586493414827e-05\n",
            "470 3.878748248098418e-05\n",
            "471 3.8415921153500676e-05\n",
            "472 3.7796475226059556e-05\n",
            "473 3.736248618224636e-05\n",
            "474 3.6825553252128884e-05\n",
            "475 3.621146606747061e-05\n",
            "476 3.5646189644467086e-05\n",
            "477 3.544275023159571e-05\n",
            "478 3.494077827781439e-05\n",
            "479 3.440449290792458e-05\n",
            "480 3.398561602807604e-05\n",
            "481 3.349298640387133e-05\n",
            "482 3.2892570743570104e-05\n",
            "483 3.2567550078965724e-05\n",
            "484 3.228092100471258e-05\n",
            "485 3.181298598065041e-05\n",
            "486 3.1398056307807565e-05\n",
            "487 3.097365333815105e-05\n",
            "488 3.0514704121742398e-05\n",
            "489 3.019873474841006e-05\n",
            "490 2.9757002266705967e-05\n",
            "491 2.9598035325761884e-05\n",
            "492 2.930078517238144e-05\n",
            "493 2.894802310038358e-05\n",
            "494 2.860144741134718e-05\n",
            "495 2.827707794494927e-05\n",
            "496 2.7943591703660786e-05\n",
            "497 2.7623584173852578e-05\n",
            "498 2.741793286986649e-05\n",
            "499 2.7033212973037735e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8TjIhMtMC4U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "412f253f-6d62-430f-fd81-5ca9e6c7b98f"
      },
      "source": [
        "model"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=1000, out_features=100, bias=False)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=100, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3F4HyagOvnS",
        "colab_type": "text"
      },
      "source": [
        "### Pytorch: optim\n",
        "这一次不再手动更新模型的weights，而是使用optim这个包来更新参数。optim这个package提供了各种不同的模型优化方法，包括SGD+momentum, RMSProp, Adam等"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORjP5E5oPDqB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0760e911-8158-41da-d98d-f047bc7c774b"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# N is batch size; D_in is input dimension;\n",
        "# H is hidden dimension; D_out is output dimension.\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "# randomly generate traning data\n",
        "x = torch.randn(N, D_in)\n",
        "y = torch.randn(N, D_out)\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(D_in, H, bias=False),  # w1 * x + b\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(H, D_out)\n",
        ")\n",
        "\n",
        "#model = model.cuda()\n",
        "\n",
        "\n",
        "loss_fn = nn.MSELoss(reduction='sum')\n",
        "learning_rate = 1e-4 # For Adam, 1e-3 to 1e-4 \n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "###############    For SGD optimizer  ########################\n",
        "# torch.nn.init.normal_(model[0].weight)  # parameter change to normal distribution to get better results\n",
        "# torch.nn.init.normal_(model[2].weight)\n",
        "# learning_rate = 1e-6  \n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "##############################################################\n",
        "\n",
        "for it in range(500):\n",
        "  #Forward pass\n",
        "  y_pred = model(x)  # model.forward()\n",
        "\n",
        "  # compute loss\n",
        "  loss = loss_fn(y_pred, y)  # loss is a computation graph\n",
        "  print(it, loss.item())\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  # Backward pass\n",
        "  loss.backward()\n",
        "\n",
        "  # update model parameters\n",
        "  optimizer.step()\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 652.4390258789062\n",
            "1 635.6054077148438\n",
            "2 619.1981201171875\n",
            "3 603.268798828125\n",
            "4 587.7530517578125\n",
            "5 572.6608276367188\n",
            "6 557.8916015625\n",
            "7 543.5771484375\n",
            "8 529.65283203125\n",
            "9 516.0699462890625\n",
            "10 502.8695983886719\n",
            "11 490.050048828125\n",
            "12 477.6190185546875\n",
            "13 465.5284729003906\n",
            "14 453.7842102050781\n",
            "15 442.4263000488281\n",
            "16 431.4237365722656\n",
            "17 420.75762939453125\n",
            "18 410.3752746582031\n",
            "19 400.2693786621094\n",
            "20 390.490966796875\n",
            "21 380.93060302734375\n",
            "22 371.67095947265625\n",
            "23 362.6505126953125\n",
            "24 353.85882568359375\n",
            "25 345.30914306640625\n",
            "26 337.02716064453125\n",
            "27 328.9324951171875\n",
            "28 321.0216979980469\n",
            "29 313.27545166015625\n",
            "30 305.68231201171875\n",
            "31 298.2498779296875\n",
            "32 290.9680480957031\n",
            "33 283.864990234375\n",
            "34 276.943115234375\n",
            "35 270.1908264160156\n",
            "36 263.5945129394531\n",
            "37 257.15625\n",
            "38 250.85145568847656\n",
            "39 244.6940155029297\n",
            "40 238.66323852539062\n",
            "41 232.7616729736328\n",
            "42 226.9816131591797\n",
            "43 221.30160522460938\n",
            "44 215.7567596435547\n",
            "45 210.33843994140625\n",
            "46 205.037353515625\n",
            "47 199.85313415527344\n",
            "48 194.78097534179688\n",
            "49 189.81680297851562\n",
            "50 184.94979858398438\n",
            "51 180.17465209960938\n",
            "52 175.52085876464844\n",
            "53 170.98736572265625\n",
            "54 166.54478454589844\n",
            "55 162.1972198486328\n",
            "56 157.92579650878906\n",
            "57 153.7420196533203\n",
            "58 149.6486053466797\n",
            "59 145.65110778808594\n",
            "60 141.73097229003906\n",
            "61 137.8892364501953\n",
            "62 134.1241455078125\n",
            "63 130.43545532226562\n",
            "64 126.82447814941406\n",
            "65 123.2911376953125\n",
            "66 119.84234619140625\n",
            "67 116.47035217285156\n",
            "68 113.16960906982422\n",
            "69 109.94196319580078\n",
            "70 106.78550720214844\n",
            "71 103.710205078125\n",
            "72 100.71385955810547\n",
            "73 97.7782211303711\n",
            "74 94.91688537597656\n",
            "75 92.1246109008789\n",
            "76 89.39485168457031\n",
            "77 86.72724914550781\n",
            "78 84.125732421875\n",
            "79 81.5911865234375\n",
            "80 79.12261199951172\n",
            "81 76.71306610107422\n",
            "82 74.36299133300781\n",
            "83 72.06818389892578\n",
            "84 69.8304672241211\n",
            "85 67.64202117919922\n",
            "86 65.50830841064453\n",
            "87 63.42550277709961\n",
            "88 61.3954963684082\n",
            "89 59.41651153564453\n",
            "90 57.48899841308594\n",
            "91 55.61323928833008\n",
            "92 53.780555725097656\n",
            "93 51.99383544921875\n",
            "94 50.257568359375\n",
            "95 48.565975189208984\n",
            "96 46.91438674926758\n",
            "97 45.30853271484375\n",
            "98 43.74632263183594\n",
            "99 42.22725296020508\n",
            "100 40.749656677246094\n",
            "101 39.31248092651367\n",
            "102 37.917510986328125\n",
            "103 36.56269073486328\n",
            "104 35.24980545043945\n",
            "105 33.97435760498047\n",
            "106 32.73685073852539\n",
            "107 31.536468505859375\n",
            "108 30.373138427734375\n",
            "109 29.246213912963867\n",
            "110 28.1567440032959\n",
            "111 27.100276947021484\n",
            "112 26.079313278198242\n",
            "113 25.091564178466797\n",
            "114 24.13678741455078\n",
            "115 23.21280288696289\n",
            "116 22.319883346557617\n",
            "117 21.456008911132812\n",
            "118 20.620758056640625\n",
            "119 19.813093185424805\n",
            "120 19.033309936523438\n",
            "121 18.279958724975586\n",
            "122 17.551673889160156\n",
            "123 16.849594116210938\n",
            "124 16.170856475830078\n",
            "125 15.515486717224121\n",
            "126 14.885367393493652\n",
            "127 14.276463508605957\n",
            "128 13.68868637084961\n",
            "129 13.122339248657227\n",
            "130 12.576126098632812\n",
            "131 12.05026626586914\n",
            "132 11.542476654052734\n",
            "133 11.05370807647705\n",
            "134 10.58360481262207\n",
            "135 10.13079833984375\n",
            "136 9.695293426513672\n",
            "137 9.276637077331543\n",
            "138 8.874528884887695\n",
            "139 8.487568855285645\n",
            "140 8.116293907165527\n",
            "141 7.76001501083374\n",
            "142 7.4171671867370605\n",
            "143 7.088322639465332\n",
            "144 6.772626876831055\n",
            "145 6.4690775871276855\n",
            "146 6.178137302398682\n",
            "147 5.899163246154785\n",
            "148 5.631603240966797\n",
            "149 5.374845504760742\n",
            "150 5.128656387329102\n",
            "151 4.892644882202148\n",
            "152 4.666713237762451\n",
            "153 4.450474262237549\n",
            "154 4.243274688720703\n",
            "155 4.045029640197754\n",
            "156 3.8552191257476807\n",
            "157 3.6736419200897217\n",
            "158 3.4999310970306396\n",
            "159 3.333813428878784\n",
            "160 3.1748812198638916\n",
            "161 3.023036003112793\n",
            "162 2.877885341644287\n",
            "163 2.7391703128814697\n",
            "164 2.6067681312561035\n",
            "165 2.480407238006592\n",
            "166 2.35968279838562\n",
            "167 2.244464874267578\n",
            "168 2.1346116065979004\n",
            "169 2.029832124710083\n",
            "170 1.9298779964447021\n",
            "171 1.8348197937011719\n",
            "172 1.744269609451294\n",
            "173 1.6579619646072388\n",
            "174 1.5756263732910156\n",
            "175 1.4972087144851685\n",
            "176 1.4225497245788574\n",
            "177 1.3514652252197266\n",
            "178 1.283656358718872\n",
            "179 1.219128966331482\n",
            "180 1.1576945781707764\n",
            "181 1.099244236946106\n",
            "182 1.043694257736206\n",
            "183 0.9907090067863464\n",
            "184 0.940314769744873\n",
            "185 0.8924200534820557\n",
            "186 0.8468987345695496\n",
            "187 0.8036063313484192\n",
            "188 0.7624191641807556\n",
            "189 0.7232790589332581\n",
            "190 0.6860020160675049\n",
            "191 0.6506469249725342\n",
            "192 0.617022693157196\n",
            "193 0.5850643515586853\n",
            "194 0.5547040104866028\n",
            "195 0.5260258913040161\n",
            "196 0.4988371431827545\n",
            "197 0.4730292856693268\n",
            "198 0.4485336244106293\n",
            "199 0.42529919743537903\n",
            "200 0.40322768688201904\n",
            "201 0.38228386640548706\n",
            "202 0.3624144494533539\n",
            "203 0.34362611174583435\n",
            "204 0.3257297873497009\n",
            "205 0.3088037669658661\n",
            "206 0.29275012016296387\n",
            "207 0.27752548456192017\n",
            "208 0.2630910575389862\n",
            "209 0.24939654767513275\n",
            "210 0.23642697930335999\n",
            "211 0.22412118315696716\n",
            "212 0.2124520242214203\n",
            "213 0.20138321816921234\n",
            "214 0.19089800119400024\n",
            "215 0.1809605360031128\n",
            "216 0.17153584957122803\n",
            "217 0.16260622441768646\n",
            "218 0.15414148569107056\n",
            "219 0.14612293243408203\n",
            "220 0.13852539658546448\n",
            "221 0.13131427764892578\n",
            "222 0.12448018789291382\n",
            "223 0.11800995469093323\n",
            "224 0.11187386512756348\n",
            "225 0.1060628741979599\n",
            "226 0.1005544513463974\n",
            "227 0.09533090144395828\n",
            "228 0.09038591384887695\n",
            "229 0.08569265156984329\n",
            "230 0.08124835789203644\n",
            "231 0.07703624665737152\n",
            "232 0.07304377108812332\n",
            "233 0.06926048547029495\n",
            "234 0.06567644327878952\n",
            "235 0.062279194593429565\n",
            "236 0.059061259031295776\n",
            "237 0.05601084604859352\n",
            "238 0.0531155951321125\n",
            "239 0.05037715286016464\n",
            "240 0.04778292030096054\n",
            "241 0.045318324118852615\n",
            "242 0.04298527538776398\n",
            "243 0.0407734289765358\n",
            "244 0.03867614269256592\n",
            "245 0.03668787330389023\n",
            "246 0.034802209585905075\n",
            "247 0.03301519155502319\n",
            "248 0.03132259100675583\n",
            "249 0.029716579243540764\n",
            "250 0.02819395437836647\n",
            "251 0.026750365272164345\n",
            "252 0.025381773710250854\n",
            "253 0.024083299562335014\n",
            "254 0.022851677611470222\n",
            "255 0.0216829814016819\n",
            "256 0.020574284717440605\n",
            "257 0.019522780552506447\n",
            "258 0.018525563180446625\n",
            "259 0.017579562962055206\n",
            "260 0.016682270914316177\n",
            "261 0.015830107033252716\n",
            "262 0.015021534636616707\n",
            "263 0.014255313202738762\n",
            "264 0.013526340946555138\n",
            "265 0.012835930101573467\n",
            "266 0.01217980682849884\n",
            "267 0.011557284742593765\n",
            "268 0.010966479778289795\n",
            "269 0.010405554436147213\n",
            "270 0.009872849099338055\n",
            "271 0.0093674436211586\n",
            "272 0.008887694217264652\n",
            "273 0.008431877009570599\n",
            "274 0.00799955241382122\n",
            "275 0.007588881067931652\n",
            "276 0.007199188694357872\n",
            "277 0.006829254329204559\n",
            "278 0.006477986462414265\n",
            "279 0.006144409999251366\n",
            "280 0.005827706307172775\n",
            "281 0.005527070723474026\n",
            "282 0.005241768434643745\n",
            "283 0.004970940761268139\n",
            "284 0.004713547881692648\n",
            "285 0.004469543229788542\n",
            "286 0.004237601067870855\n",
            "287 0.004017574712634087\n",
            "288 0.0038087046705186367\n",
            "289 0.003610409563407302\n",
            "290 0.0034221545793116093\n",
            "291 0.0032435408793389797\n",
            "292 0.003073954489082098\n",
            "293 0.0029130643233656883\n",
            "294 0.0027602699119597673\n",
            "295 0.0026153314393013716\n",
            "296 0.00247780024074018\n",
            "297 0.0023473151959478855\n",
            "298 0.0022234434727579355\n",
            "299 0.0021059417631477118\n",
            "300 0.001994500868022442\n",
            "301 0.0018887660698965192\n",
            "302 0.0017884572735056281\n",
            "303 0.001693282974883914\n",
            "304 0.0016030198894441128\n",
            "305 0.0015174588188529015\n",
            "306 0.0014362666988745332\n",
            "307 0.001359289395622909\n",
            "308 0.0012863387819379568\n",
            "309 0.001217120559886098\n",
            "310 0.0011515460209921002\n",
            "311 0.0010893864091485739\n",
            "312 0.0010304755996912718\n",
            "313 0.0009746411233209074\n",
            "314 0.0009217256447300315\n",
            "315 0.000871619617100805\n",
            "316 0.0008240863680839539\n",
            "317 0.0007791283424012363\n",
            "318 0.0007365391356870532\n",
            "319 0.0006961904582567513\n",
            "320 0.0006579848704859614\n",
            "321 0.0006218264461494982\n",
            "322 0.0005875361384823918\n",
            "323 0.0005550980567932129\n",
            "324 0.0005243928753770888\n",
            "325 0.0004953212919645011\n",
            "326 0.0004678116529248655\n",
            "327 0.00044175918446853757\n",
            "328 0.000417120783822611\n",
            "329 0.00039381362148560584\n",
            "330 0.0003717489307746291\n",
            "331 0.00035088424920104444\n",
            "332 0.0003311496984679252\n",
            "333 0.00031248797313310206\n",
            "334 0.0002948349283542484\n",
            "335 0.0002781504881568253\n",
            "336 0.00026237237034365535\n",
            "337 0.0002474612556397915\n",
            "338 0.0002333640295546502\n",
            "339 0.00022004343918524683\n",
            "340 0.00020745913207065314\n",
            "341 0.00019556762708816677\n",
            "342 0.0001843301288317889\n",
            "343 0.00017372101137880236\n",
            "344 0.00016370082448702306\n",
            "345 0.00015423493459820747\n",
            "346 0.00014530002954415977\n",
            "347 0.00013686181046068668\n",
            "348 0.000128905798192136\n",
            "349 0.000121385368402116\n",
            "350 0.00011429455480538309\n",
            "351 0.00010759945871541277\n",
            "352 0.00010129209840670228\n",
            "353 9.533106640446931e-05\n",
            "354 8.971361967269331e-05\n",
            "355 8.441532554570585e-05\n",
            "356 7.941799412947148e-05\n",
            "357 7.470620766980574e-05\n",
            "358 7.026565435808152e-05\n",
            "359 6.60848236293532e-05\n",
            "360 6.21354702161625e-05\n",
            "361 5.841815072926693e-05\n",
            "362 5.491529009304941e-05\n",
            "363 5.1616880227811635e-05\n",
            "364 4.85072705487255e-05\n",
            "365 4.55810732091777e-05\n",
            "366 4.2827963625313714e-05\n",
            "367 4.022932625957765e-05\n",
            "368 3.7786583561683074e-05\n",
            "369 3.5486136766849086e-05\n",
            "370 3.33210700773634e-05\n",
            "371 3.128297976218164e-05\n",
            "372 2.936856253654696e-05\n",
            "373 2.756473986664787e-05\n",
            "374 2.587131893960759e-05\n",
            "375 2.4274926545331255e-05\n",
            "376 2.2777954654884525e-05\n",
            "377 2.136733201041352e-05\n",
            "378 2.0039817172801122e-05\n",
            "379 1.879367118817754e-05\n",
            "380 1.7622107407078147e-05\n",
            "381 1.652279206609819e-05\n",
            "382 1.5487945347558707e-05\n",
            "383 1.4517521776724607e-05\n",
            "384 1.3603912520920858e-05\n",
            "385 1.2747293112624902e-05\n",
            "386 1.1942189303226769e-05\n",
            "387 1.1188202734047081e-05\n",
            "388 1.0478106560185552e-05\n",
            "389 9.812743883230723e-06\n",
            "390 9.1880128820776e-06\n",
            "391 8.602303751104046e-06\n",
            "392 8.05116451374488e-06\n",
            "393 7.535224540333729e-06\n",
            "394 7.05185493643512e-06\n",
            "395 6.597441370104207e-06\n",
            "396 6.1718851611658465e-06\n",
            "397 5.773406883236021e-06\n",
            "398 5.399914698500652e-06\n",
            "399 5.049534593126737e-06\n",
            "400 4.720497599919327e-06\n",
            "401 4.413142960402183e-06\n",
            "402 4.124807674088515e-06\n",
            "403 3.854898750432767e-06\n",
            "404 3.6020835523231653e-06\n",
            "405 3.364606300237938e-06\n",
            "406 3.1433387448487338e-06\n",
            "407 2.9360253392951563e-06\n",
            "408 2.741432126640575e-06\n",
            "409 2.5591634766897187e-06\n",
            "410 2.389887185927364e-06\n",
            "411 2.2303772766463226e-06\n",
            "412 2.081504135276191e-06\n",
            "413 1.942432618307066e-06\n",
            "414 1.812573941606388e-06\n",
            "415 1.690675730969815e-06\n",
            "416 1.5768531511639594e-06\n",
            "417 1.4708544995301054e-06\n",
            "418 1.37085066853615e-06\n",
            "419 1.2777452411683043e-06\n",
            "420 1.191288561130932e-06\n",
            "421 1.110566699935589e-06\n",
            "422 1.0345114560550428e-06\n",
            "423 9.64042669693299e-07\n",
            "424 8.978987011687423e-07\n",
            "425 8.360658512174268e-07\n",
            "426 7.788050879753428e-07\n",
            "427 7.250976068462478e-07\n",
            "428 6.750693728463375e-07\n",
            "429 6.281791229412192e-07\n",
            "430 5.847921897839115e-07\n",
            "431 5.438692483039631e-07\n",
            "432 5.061326646682573e-07\n",
            "433 4.7106510692174197e-07\n",
            "434 4.381253688734432e-07\n",
            "435 4.070407726430858e-07\n",
            "436 3.787393723087007e-07\n",
            "437 3.518593416629301e-07\n",
            "438 3.2725824894441757e-07\n",
            "439 3.0403259643208003e-07\n",
            "440 2.8264557272450475e-07\n",
            "441 2.623716568450618e-07\n",
            "442 2.43621769868696e-07\n",
            "443 2.2642957731022761e-07\n",
            "444 2.1020245810632332e-07\n",
            "445 1.952917045855429e-07\n",
            "446 1.8123039069450897e-07\n",
            "447 1.6828643367716722e-07\n",
            "448 1.5617402482348552e-07\n",
            "449 1.4473936005288124e-07\n",
            "450 1.3440234170047916e-07\n",
            "451 1.2474546906560136e-07\n",
            "452 1.1565575164240727e-07\n",
            "453 1.0724029664288537e-07\n",
            "454 9.939920886381515e-08\n",
            "455 9.220064356441071e-08\n",
            "456 8.545475793653168e-08\n",
            "457 7.925857659074609e-08\n",
            "458 7.340234731145756e-08\n",
            "459 6.78954705790602e-08\n",
            "460 6.289906906431497e-08\n",
            "461 5.8269300495794596e-08\n",
            "462 5.3961322521445254e-08\n",
            "463 4.998025104896442e-08\n",
            "464 4.623806049153245e-08\n",
            "465 4.2838045999360475e-08\n",
            "466 3.9674365126529665e-08\n",
            "467 3.660266756355668e-08\n",
            "468 3.38906396279981e-08\n",
            "469 3.1443700976296896e-08\n",
            "470 2.9048401017917058e-08\n",
            "471 2.6861492585794622e-08\n",
            "472 2.4890148608847085e-08\n",
            "473 2.3016324846025782e-08\n",
            "474 2.1231958413636676e-08\n",
            "475 1.9634411430047294e-08\n",
            "476 1.815194217158478e-08\n",
            "477 1.6807543801178326e-08\n",
            "478 1.5542379827593322e-08\n",
            "479 1.436461349868523e-08\n",
            "480 1.3287264621908434e-08\n",
            "481 1.2293844164901202e-08\n",
            "482 1.1352642381723399e-08\n",
            "483 1.0485186052733297e-08\n",
            "484 9.708369219652013e-09\n",
            "485 8.961035469212675e-09\n",
            "486 8.295653053380647e-09\n",
            "487 7.648592870168613e-09\n",
            "488 7.094245191296977e-09\n",
            "489 6.558287246605232e-09\n",
            "490 6.0853180272602e-09\n",
            "491 5.630769184250539e-09\n",
            "492 5.216610698965951e-09\n",
            "493 4.809070031086549e-09\n",
            "494 4.444044243712142e-09\n",
            "495 4.138589915214652e-09\n",
            "496 3.828418027040925e-09\n",
            "497 3.5362566208618773e-09\n",
            "498 3.2977305330916806e-09\n",
            "499 3.0558555685900046e-09\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvLEfS7vQzii",
        "colab_type": "text"
      },
      "source": [
        "### Pytorch: 自定义nn Modules\n",
        "\n",
        "定义一个模型，这个模型继承自nn.Module类。如果需要定义一个比Sequential模型更加复杂的模型，就需要定义nn.Module模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0h8Z5eNRPCZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a0edb33d-4dae-4f9e-fa35-d0bc47f4265b"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# N is batch size; D_in is input dimension;\n",
        "# H is hidden dimension; D_out is output dimension.\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "# randomly generate traning data\n",
        "x = torch.randn(N, D_in)\n",
        "y = torch.randn(N, D_out)\n",
        "\n",
        "class TwoLayerNet(torch.nn.Module):\n",
        "  def __init__(self, D_in, H, D_out):\n",
        "    super(TwoLayerNet, self).__init__()\n",
        "    self.linear1 = torch.nn.Linear(D_in, H, bias=False)\n",
        "    self.linear2 = torch.nn.Linear(H, D_out, bias=False)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    y_pred = self.linear2(self.linear1(x).clamp(min=0))\n",
        "    return y_pred\n",
        "\n",
        "model = TwoLayerNet(D_in, H, D_out)\n",
        "\n",
        "#model = model.cuda()\n",
        "\n",
        "loss_fn = nn.MSELoss(reduction='sum')\n",
        "learning_rate = 1e-4 # For Adam, 1e-3 to 1e-4 \n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for it in range(500):\n",
        "  #Forward pass\n",
        "  y_pred = model(x)  # model.forward()\n",
        "\n",
        "  # compute loss\n",
        "  loss = loss_fn(y_pred, y)  # loss is a computation graph\n",
        "  print(it, loss.item())\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  # Backward pass\n",
        "  loss.backward()\n",
        "\n",
        "  # update model parameters\n",
        "  optimizer.step()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 639.626220703125\n",
            "1 623.183837890625\n",
            "2 607.157958984375\n",
            "3 591.58642578125\n",
            "4 576.4970092773438\n",
            "5 561.8151245117188\n",
            "6 547.5734252929688\n",
            "7 533.7909545898438\n",
            "8 520.4666137695312\n",
            "9 507.63165283203125\n",
            "10 495.24151611328125\n",
            "11 483.2508239746094\n",
            "12 471.6859130859375\n",
            "13 460.52008056640625\n",
            "14 449.65966796875\n",
            "15 439.13238525390625\n",
            "16 428.91558837890625\n",
            "17 418.9555969238281\n",
            "18 409.2950439453125\n",
            "19 399.8929748535156\n",
            "20 390.734619140625\n",
            "21 381.8029479980469\n",
            "22 373.12005615234375\n",
            "23 364.7010498046875\n",
            "24 356.5187683105469\n",
            "25 348.5360412597656\n",
            "26 340.7286682128906\n",
            "27 333.09027099609375\n",
            "28 325.6412353515625\n",
            "29 318.3617858886719\n",
            "30 311.21832275390625\n",
            "31 304.2663269042969\n",
            "32 297.4598388671875\n",
            "33 290.76763916015625\n",
            "34 284.2041015625\n",
            "35 277.802001953125\n",
            "36 271.5396728515625\n",
            "37 265.41552734375\n",
            "38 259.42535400390625\n",
            "39 253.5589141845703\n",
            "40 247.837646484375\n",
            "41 242.22256469726562\n",
            "42 236.72103881835938\n",
            "43 231.32748413085938\n",
            "44 226.05633544921875\n",
            "45 220.90721130371094\n",
            "46 215.87155151367188\n",
            "47 210.92385864257812\n",
            "48 206.09268188476562\n",
            "49 201.365234375\n",
            "50 196.73220825195312\n",
            "51 192.19198608398438\n",
            "52 187.73175048828125\n",
            "53 183.35948181152344\n",
            "54 179.0773468017578\n",
            "55 174.8775177001953\n",
            "56 170.76675415039062\n",
            "57 166.7362518310547\n",
            "58 162.77700805664062\n",
            "59 158.90460205078125\n",
            "60 155.1123046875\n",
            "61 151.39437866210938\n",
            "62 147.74212646484375\n",
            "63 144.17677307128906\n",
            "64 140.68028259277344\n",
            "65 137.2603302001953\n",
            "66 133.916015625\n",
            "67 130.64053344726562\n",
            "68 127.42732238769531\n",
            "69 124.28124237060547\n",
            "70 121.20442199707031\n",
            "71 118.18867492675781\n",
            "72 115.2326431274414\n",
            "73 112.33670043945312\n",
            "74 109.5005111694336\n",
            "75 106.725830078125\n",
            "76 104.01020812988281\n",
            "77 101.35084533691406\n",
            "78 98.74174499511719\n",
            "79 96.18954467773438\n",
            "80 93.70036315917969\n",
            "81 91.26641845703125\n",
            "82 88.88188171386719\n",
            "83 86.55693054199219\n",
            "84 84.27750396728516\n",
            "85 82.04761505126953\n",
            "86 79.87265014648438\n",
            "87 77.74981689453125\n",
            "88 75.66850280761719\n",
            "89 73.63501739501953\n",
            "90 71.65107727050781\n",
            "91 69.704345703125\n",
            "92 67.80281829833984\n",
            "93 65.94298553466797\n",
            "94 64.12940979003906\n",
            "95 62.35454559326172\n",
            "96 60.622711181640625\n",
            "97 58.93010330200195\n",
            "98 57.276424407958984\n",
            "99 55.66240692138672\n",
            "100 54.08336639404297\n",
            "101 52.53917694091797\n",
            "102 51.033546447753906\n",
            "103 49.562828063964844\n",
            "104 48.1253662109375\n",
            "105 46.72703170776367\n",
            "106 45.360816955566406\n",
            "107 44.02760696411133\n",
            "108 42.72822952270508\n",
            "109 41.457550048828125\n",
            "110 40.222503662109375\n",
            "111 39.014652252197266\n",
            "112 37.83935546875\n",
            "113 36.69325256347656\n",
            "114 35.5776481628418\n",
            "115 34.49310302734375\n",
            "116 33.43429946899414\n",
            "117 32.40353012084961\n",
            "118 31.400333404541016\n",
            "119 30.425453186035156\n",
            "120 29.478046417236328\n",
            "121 28.55501937866211\n",
            "122 27.658550262451172\n",
            "123 26.787057876586914\n",
            "124 25.940378189086914\n",
            "125 25.1175594329834\n",
            "126 24.31768035888672\n",
            "127 23.539783477783203\n",
            "128 22.784107208251953\n",
            "129 22.049142837524414\n",
            "130 21.333175659179688\n",
            "131 20.637897491455078\n",
            "132 19.96098518371582\n",
            "133 19.302303314208984\n",
            "134 18.662643432617188\n",
            "135 18.04218292236328\n",
            "136 17.437198638916016\n",
            "137 16.85178565979004\n",
            "138 16.28338050842285\n",
            "139 15.73324203491211\n",
            "140 15.198210716247559\n",
            "141 14.68037223815918\n",
            "142 14.17874526977539\n",
            "143 13.692265510559082\n",
            "144 13.22046947479248\n",
            "145 12.763694763183594\n",
            "146 12.321149826049805\n",
            "147 11.892742156982422\n",
            "148 11.477863311767578\n",
            "149 11.076271057128906\n",
            "150 10.68744945526123\n",
            "151 10.310820579528809\n",
            "152 9.946253776550293\n",
            "153 9.593640327453613\n",
            "154 9.252779006958008\n",
            "155 8.922589302062988\n",
            "156 8.603551864624023\n",
            "157 8.294646263122559\n",
            "158 7.996422290802002\n",
            "159 7.708488464355469\n",
            "160 7.430424690246582\n",
            "161 7.161417484283447\n",
            "162 6.9015913009643555\n",
            "163 6.649855136871338\n",
            "164 6.406805992126465\n",
            "165 6.171201705932617\n",
            "166 5.943084239959717\n",
            "167 5.722492694854736\n",
            "168 5.508730411529541\n",
            "169 5.302186012268066\n",
            "170 5.102661609649658\n",
            "171 4.909958362579346\n",
            "172 4.723361968994141\n",
            "173 4.543330192565918\n",
            "174 4.369677543640137\n",
            "175 4.202099800109863\n",
            "176 4.040389060974121\n",
            "177 3.884298086166382\n",
            "178 3.7340290546417236\n",
            "179 3.5893146991729736\n",
            "180 3.449782609939575\n",
            "181 3.315279722213745\n",
            "182 3.1857657432556152\n",
            "183 3.061049461364746\n",
            "184 2.9409027099609375\n",
            "185 2.825249671936035\n",
            "186 2.7139461040496826\n",
            "187 2.606858730316162\n",
            "188 2.5038681030273438\n",
            "189 2.404627799987793\n",
            "190 2.3091349601745605\n",
            "191 2.2173948287963867\n",
            "192 2.129187822341919\n",
            "193 2.044341564178467\n",
            "194 1.9628793001174927\n",
            "195 1.8845264911651611\n",
            "196 1.8091609477996826\n",
            "197 1.7367802858352661\n",
            "198 1.667325735092163\n",
            "199 1.6006789207458496\n",
            "200 1.536644697189331\n",
            "201 1.4751253128051758\n",
            "202 1.4160408973693848\n",
            "203 1.3593186140060425\n",
            "204 1.3048276901245117\n",
            "205 1.2525237798690796\n",
            "206 1.2022861242294312\n",
            "207 1.1540601253509521\n",
            "208 1.1077566146850586\n",
            "209 1.0633442401885986\n",
            "210 1.0206494331359863\n",
            "211 0.9796987771987915\n",
            "212 0.9404071569442749\n",
            "213 0.9026708602905273\n",
            "214 0.8664546012878418\n",
            "215 0.8317746520042419\n",
            "216 0.7984725832939148\n",
            "217 0.7665116190910339\n",
            "218 0.7358416318893433\n",
            "219 0.7064248323440552\n",
            "220 0.6782646775245667\n",
            "221 0.651164174079895\n",
            "222 0.6251819133758545\n",
            "223 0.600292980670929\n",
            "224 0.576408326625824\n",
            "225 0.5534785389900208\n",
            "226 0.5314992070198059\n",
            "227 0.5104237794876099\n",
            "228 0.49019983410835266\n",
            "229 0.47081756591796875\n",
            "230 0.4522198438644409\n",
            "231 0.43442028760910034\n",
            "232 0.41735225915908813\n",
            "233 0.40097561478614807\n",
            "234 0.3852611184120178\n",
            "235 0.3701878488063812\n",
            "236 0.35575777292251587\n",
            "237 0.3419243097305298\n",
            "238 0.32865363359451294\n",
            "239 0.3158900737762451\n",
            "240 0.3036584258079529\n",
            "241 0.29191410541534424\n",
            "242 0.28065618872642517\n",
            "243 0.2698405385017395\n",
            "244 0.2594578266143799\n",
            "245 0.24948887526988983\n",
            "246 0.23991641402244568\n",
            "247 0.23072905838489532\n",
            "248 0.22189928591251373\n",
            "249 0.213421031832695\n",
            "250 0.2052862048149109\n",
            "251 0.19747161865234375\n",
            "252 0.18995623290538788\n",
            "253 0.18274229764938354\n",
            "254 0.17580491304397583\n",
            "255 0.16914556920528412\n",
            "256 0.1627407670021057\n",
            "257 0.15659159421920776\n",
            "258 0.15067678689956665\n",
            "259 0.14498905837535858\n",
            "260 0.13952280580997467\n",
            "261 0.13427051901817322\n",
            "262 0.1292153149843216\n",
            "263 0.12436001747846603\n",
            "264 0.11968720704317093\n",
            "265 0.11519463360309601\n",
            "266 0.11087220907211304\n",
            "267 0.1067112609744072\n",
            "268 0.10270781815052032\n",
            "269 0.09885545074939728\n",
            "270 0.09514803439378738\n",
            "271 0.09158185869455338\n",
            "272 0.08814892917871475\n",
            "273 0.08484461903572083\n",
            "274 0.0816650316119194\n",
            "275 0.07860645651817322\n",
            "276 0.0756583884358406\n",
            "277 0.072822704911232\n",
            "278 0.07009296119213104\n",
            "279 0.06746292859315872\n",
            "280 0.06493282318115234\n",
            "281 0.06249523162841797\n",
            "282 0.060149725526571274\n",
            "283 0.05789004638791084\n",
            "284 0.05571361631155014\n",
            "285 0.05361764505505562\n",
            "286 0.051598962396383286\n",
            "287 0.04965558648109436\n",
            "288 0.04778344929218292\n",
            "289 0.04598001763224602\n",
            "290 0.0442432202398777\n",
            "291 0.042569391429424286\n",
            "292 0.040957577526569366\n",
            "293 0.0394052118062973\n",
            "294 0.03791007399559021\n",
            "295 0.03649470955133438\n",
            "296 0.03513651341199875\n",
            "297 0.03383011743426323\n",
            "298 0.0325726717710495\n",
            "299 0.03136192634701729\n",
            "300 0.030196912586688995\n",
            "301 0.029075197875499725\n",
            "302 0.02799592912197113\n",
            "303 0.026956235989928246\n",
            "304 0.02595524676144123\n",
            "305 0.024990124627947807\n",
            "306 0.024059351533651352\n",
            "307 0.02316148206591606\n",
            "308 0.022295281291007996\n",
            "309 0.021459847688674927\n",
            "310 0.0206543430685997\n",
            "311 0.019877735525369644\n",
            "312 0.019129140302538872\n",
            "313 0.01840764842927456\n",
            "314 0.017712587490677834\n",
            "315 0.017042573541402817\n",
            "316 0.016397185623645782\n",
            "317 0.01577557809650898\n",
            "318 0.015176800079643726\n",
            "319 0.014599828980863094\n",
            "320 0.014044190756976604\n",
            "321 0.013509189710021019\n",
            "322 0.012993856333196163\n",
            "323 0.01249795500189066\n",
            "324 0.012019950896501541\n",
            "325 0.011559831909835339\n",
            "326 0.011117016896605492\n",
            "327 0.010690344497561455\n",
            "328 0.01027968991547823\n",
            "329 0.009884319268167019\n",
            "330 0.009503611363470554\n",
            "331 0.009137013927102089\n",
            "332 0.008784078992903233\n",
            "333 0.008444351144134998\n",
            "334 0.00811726599931717\n",
            "335 0.007802326697856188\n",
            "336 0.007499009370803833\n",
            "337 0.007207083515822887\n",
            "338 0.006926107686012983\n",
            "339 0.006655613426119089\n",
            "340 0.006395179312676191\n",
            "341 0.006144573912024498\n",
            "342 0.005903269164264202\n",
            "343 0.0056710271164774895\n",
            "344 0.0054474687203764915\n",
            "345 0.005232449155300856\n",
            "346 0.005025302525609732\n",
            "347 0.004826089832931757\n",
            "348 0.004634310491383076\n",
            "349 0.0044498383067548275\n",
            "350 0.004272345919162035\n",
            "351 0.004101601894944906\n",
            "352 0.003937290050089359\n",
            "353 0.003779207356274128\n",
            "354 0.003627185709774494\n",
            "355 0.0034809494391083717\n",
            "356 0.0033403178676962852\n",
            "357 0.003205064218491316\n",
            "358 0.0030749745201319456\n",
            "359 0.0029498934745788574\n",
            "360 0.002829654375091195\n",
            "361 0.002714053262025118\n",
            "362 0.0026029134169220924\n",
            "363 0.0024961004965007305\n",
            "364 0.002393486211076379\n",
            "365 0.002294820500537753\n",
            "366 0.0022000300232321024\n",
            "367 0.0021089338697493076\n",
            "368 0.0020214137621223927\n",
            "369 0.0019373787799850106\n",
            "370 0.0018567005172371864\n",
            "371 0.0017792517319321632\n",
            "372 0.001704830676317215\n",
            "373 0.0016333559760823846\n",
            "374 0.0015647701220586896\n",
            "375 0.0014988924376666546\n",
            "376 0.001435662037692964\n",
            "377 0.0013749586651101708\n",
            "378 0.0013167071156203747\n",
            "379 0.0012607740936800838\n",
            "380 0.0012071379460394382\n",
            "381 0.0011556092649698257\n",
            "382 0.0011062277480959892\n",
            "383 0.0010588220320641994\n",
            "384 0.0010133597534149885\n",
            "385 0.0009697546483948827\n",
            "386 0.0009279220248572528\n",
            "387 0.000887820206116885\n",
            "388 0.0008493539644405246\n",
            "389 0.0008124905871227384\n",
            "390 0.0007771337986923754\n",
            "391 0.0007432615966536105\n",
            "392 0.0007107881247065961\n",
            "393 0.0006796586094424129\n",
            "394 0.0006498234579339623\n",
            "395 0.0006212489097379148\n",
            "396 0.000593868549913168\n",
            "397 0.000567642564419657\n",
            "398 0.0005425155395641923\n",
            "399 0.0005184379406273365\n",
            "400 0.0004953851457685232\n",
            "401 0.0004733185633085668\n",
            "402 0.0004521941300481558\n",
            "403 0.0004319508734624833\n",
            "404 0.00041258055716753006\n",
            "405 0.0003940435708500445\n",
            "406 0.0003762961132451892\n",
            "407 0.0003593128640204668\n",
            "408 0.00034306818270124495\n",
            "409 0.000327517424011603\n",
            "410 0.0003126391093246639\n",
            "411 0.0002984082093462348\n",
            "412 0.00028479486354626715\n",
            "413 0.0002717898169066757\n",
            "414 0.00025933695724233985\n",
            "415 0.0002474313077982515\n",
            "416 0.0002360479993512854\n",
            "417 0.00022516833269037306\n",
            "418 0.00021477710106410086\n",
            "419 0.00020483364642132074\n",
            "420 0.00019533830345608294\n",
            "421 0.00018625325174070895\n",
            "422 0.00017758156172931194\n",
            "423 0.00016929472621995956\n",
            "424 0.00016137701459228992\n",
            "425 0.00015381556295324117\n",
            "426 0.00014659346197731793\n",
            "427 0.00013969284191261977\n",
            "428 0.00013310361828189343\n",
            "429 0.00012681924272328615\n",
            "430 0.00012081314343959093\n",
            "431 0.00011508289026096463\n",
            "432 0.00010960861254716292\n",
            "433 0.00010438638855703175\n",
            "434 9.940583549905568e-05\n",
            "435 9.465048060519621e-05\n",
            "436 9.011381916934624e-05\n",
            "437 8.578691631555557e-05\n",
            "438 8.165711187757552e-05\n",
            "439 7.772060780553147e-05\n",
            "440 7.396504952339455e-05\n",
            "441 7.038586045382544e-05\n",
            "442 6.696773925796151e-05\n",
            "443 6.371355266310275e-05\n",
            "444 6.0608756029978395e-05\n",
            "445 5.765134847024456e-05\n",
            "446 5.4830306908115745e-05\n",
            "447 5.2141956984996796e-05\n",
            "448 4.958079807693139e-05\n",
            "449 4.714325041277334e-05\n",
            "450 4.482046642806381e-05\n",
            "451 4.260889545548707e-05\n",
            "452 4.049788185511716e-05\n",
            "453 3.848765481961891e-05\n",
            "454 3.6576537240762264e-05\n",
            "455 3.4754411899484694e-05\n",
            "456 3.3022224670276046e-05\n",
            "457 3.137030216748826e-05\n",
            "458 2.979887358378619e-05\n",
            "459 2.8303606086410582e-05\n",
            "460 2.688084168767091e-05\n",
            "461 2.552412115619518e-05\n",
            "462 2.4238135665655136e-05\n",
            "463 2.3010325094219297e-05\n",
            "464 2.1845076844329014e-05\n",
            "465 2.0734956706291996e-05\n",
            "466 1.9681396224768832e-05\n",
            "467 1.867674473032821e-05\n",
            "468 1.7723015844239853e-05\n",
            "469 1.6817539290059358e-05\n",
            "470 1.595385401742533e-05\n",
            "471 1.5134472050704062e-05\n",
            "472 1.4354455743159633e-05\n",
            "473 1.361380964226555e-05\n",
            "474 1.2911645171698183e-05\n",
            "475 1.2242338925716467e-05\n",
            "476 1.1607209671637975e-05\n",
            "477 1.1003841791534796e-05\n",
            "478 1.0431517694087233e-05\n",
            "479 9.886100997391623e-06\n",
            "480 9.369983672513627e-06\n",
            "481 8.877933396433946e-06\n",
            "482 8.412445822614245e-06\n",
            "483 7.970049409777857e-06\n",
            "484 7.550303052994423e-06\n",
            "485 7.151624686230207e-06\n",
            "486 6.772908818675205e-06\n",
            "487 6.41445967630716e-06\n",
            "488 6.074783868825762e-06\n",
            "489 5.750376203650376e-06\n",
            "490 5.444665475806687e-06\n",
            "491 5.1528518270060886e-06\n",
            "492 4.877524588664528e-06\n",
            "493 4.615992111212108e-06\n",
            "494 4.367699602880748e-06\n",
            "495 4.1334624256705865e-06\n",
            "496 3.910241048288299e-06\n",
            "497 3.698697810250451e-06\n",
            "498 3.4980616874236148e-06\n",
            "499 3.3089431781263556e-06\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}